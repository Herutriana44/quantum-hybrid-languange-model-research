{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install qiskit qiskit-machine-learning"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fGJmt12e0wfD",
        "outputId": "58062368-f78a-4dbc-918d-97a79d6467c1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting qiskit\n",
            "  Downloading qiskit-1.3.2-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting qiskit-machine-learning\n",
            "  Downloading qiskit_machine_learning-0.8.2-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting rustworkx>=0.15.0 (from qiskit)\n",
            "  Downloading rustworkx-0.16.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (10 kB)\n",
            "Requirement already satisfied: numpy<3,>=1.17 in /usr/local/lib/python3.11/dist-packages (from qiskit) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.5 in /usr/local/lib/python3.11/dist-packages (from qiskit) (1.13.1)\n",
            "Requirement already satisfied: sympy>=1.3 in /usr/local/lib/python3.11/dist-packages (from qiskit) (1.13.1)\n",
            "Collecting dill>=0.3 (from qiskit)\n",
            "  Downloading dill-0.3.9-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.8.0 in /usr/local/lib/python3.11/dist-packages (from qiskit) (2.8.2)\n",
            "Collecting stevedore>=3.0.0 (from qiskit)\n",
            "  Downloading stevedore-5.4.0-py3-none-any.whl.metadata (2.3 kB)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from qiskit) (4.12.2)\n",
            "Collecting symengine<0.14,>=0.11 (from qiskit)\n",
            "  Downloading symengine-0.13.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.2 kB)\n",
            "Requirement already satisfied: psutil>=5 in /usr/local/lib/python3.11/dist-packages (from qiskit-machine-learning) (5.9.5)\n",
            "Requirement already satisfied: scikit-learn>=1.2 in /usr/local/lib/python3.11/dist-packages (from qiskit-machine-learning) (1.6.1)\n",
            "Requirement already satisfied: setuptools>=40.1 in /usr/local/lib/python3.11/dist-packages (from qiskit-machine-learning) (75.1.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.0->qiskit) (1.17.0)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.2->qiskit-machine-learning) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.2->qiskit-machine-learning) (3.5.0)\n",
            "Collecting pbr>=2.0.0 (from stevedore>=3.0.0->qiskit)\n",
            "  Downloading pbr-6.1.1-py2.py3-none-any.whl.metadata (3.4 kB)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy>=1.3->qiskit) (1.3.0)\n",
            "Downloading qiskit-1.3.2-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.8/6.8 MB\u001b[0m \u001b[31m50.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading qiskit_machine_learning-0.8.2-py3-none-any.whl (231 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m231.6/231.6 kB\u001b[0m \u001b[31m16.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dill-0.3.9-py3-none-any.whl (119 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m119.4/119.4 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading rustworkx-0.16.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m58.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading stevedore-5.4.0-py3-none-any.whl (49 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.5/49.5 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading symengine-0.13.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (49.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.7/49.7 MB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pbr-6.1.1-py2.py3-none-any.whl (108 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m109.0/109.0 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: symengine, rustworkx, pbr, dill, stevedore, qiskit, qiskit-machine-learning\n",
            "Successfully installed dill-0.3.9 pbr-6.1.1 qiskit-1.3.2 qiskit-machine-learning-0.8.2 rustworkx-0.16.0 stevedore-5.4.0 symengine-0.13.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from qiskit import QuantumCircuit\n",
        "from qiskit.circuit.library import ZZFeatureMap, RealAmplitudes\n",
        "from qiskit_machine_learning.neural_networks import EstimatorQNN\n",
        "from qiskit.primitives import Estimator"
      ],
      "metadata": {
        "id": "xnsxb5Im00FK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Inisialisasi estimator\n",
        "estimator = Estimator()\n",
        "\n",
        "# Fungsi untuk membuat Quantum Neural Network (QNN)\n",
        "def qnn1():\n",
        "    feature_map = ZZFeatureMap(2)\n",
        "    ansatz = RealAmplitudes(2, reps=1)\n",
        "    qc = QuantumCircuit(2)\n",
        "    qc.compose(feature_map, inplace=True)\n",
        "    qc.compose(ansatz, inplace=True)\n",
        "\n",
        "    # Mengaktifkan input_gradients untuk backprop hybrid gradient\n",
        "    qnn = EstimatorQNN(\n",
        "        circuit=qc,\n",
        "        input_params=feature_map.parameters,\n",
        "        weight_params=ansatz.parameters,\n",
        "        input_gradients=True,\n",
        "        estimator=estimator,\n",
        "    )\n",
        "    return qnn\n",
        "\n",
        "# Membuat QNN\n",
        "qnn4 = qnn1()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D37NY_1Y02yt",
        "outputId": "e3cd9db8-ae44-42d9-834c-1d883fd210aa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-11-fe9bf4fc5da2>:2: DeprecationWarning: The class ``qiskit.primitives.estimator.Estimator`` is deprecated as of qiskit 1.2. It will be removed no earlier than 3 months after the release date. All implementations of the `BaseEstimatorV1` interface have been deprecated in favor of their V2 counterparts. The V2 alternative for the `Estimator` class is `StatevectorEstimator`.\n",
            "  estimator = Estimator()\n",
            "<ipython-input-11-fe9bf4fc5da2>:13: DeprecationWarning: V1 Primitives are deprecated as of qiskit-machine-learning 0.8.0 and will be removed no sooner than 4 months after the release date. Use V2 primitives for continued compatibility and support.\n",
            "  qnn = EstimatorQNN(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "qnn4"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m6XpDtBD07Ya",
        "outputId": "48555492-8c16-4feb-c6ad-0881351d34fd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<qiskit_machine_learning.neural_networks.estimator_qnn.EstimatorQNN at 0x7eb51b7e7250>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BEepoM_BzjPo"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from qiskit import QuantumCircuit\n",
        "from qiskit.circuit.library import ZZFeatureMap, RealAmplitudes\n",
        "from qiskit_machine_learning.neural_networks import EstimatorQNN\n",
        "from qiskit.primitives import Estimator\n",
        "\n",
        "class GPTBlock(nn.Module):\n",
        "    def __init__(self, embed_size, heads, dropout, forward_expansion):\n",
        "        super(GPTBlock, self).__init__()\n",
        "        self.attention = nn.MultiheadAttention(embed_dim=embed_size, num_heads=heads, batch_first=True)\n",
        "        self.norm1 = nn.LayerNorm(embed_size)\n",
        "        self.norm2 = nn.LayerNorm(embed_size)\n",
        "        self.feed_forward = nn.Sequential(\n",
        "            nn.Linear(embed_size, forward_expansion * embed_size),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(forward_expansion * embed_size, embed_size)\n",
        "        )\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x, mask):\n",
        "        print(\"\\n===== FORWARD PASS GPTBlock =====\")\n",
        "        print(f\"Input tensor shape: {x.shape}\")\n",
        "\n",
        "        attn_output, _ = self.attention(x, x, x, attn_mask=mask)\n",
        "        print(f\"Attention output shape: {attn_output.shape}\")\n",
        "        print(f\"Attention output values:\\n {attn_output}\")\n",
        "\n",
        "        x = self.norm1(x + self.dropout(attn_output))\n",
        "        print(f\"After LayerNorm1 shape: {x.shape}\")\n",
        "        print(f\"After LayerNorm1 values:\\n {x}\")\n",
        "\n",
        "        forward_out = self.feed_forward(x)\n",
        "        print(f\"Feed Forward output shape: {forward_out.shape}\")\n",
        "        print(f\"Feed Forward output values:\\n {forward_out}\")\n",
        "\n",
        "        out = self.norm2(x + self.dropout(forward_out))\n",
        "        print(f\"After LayerNorm2 shape: {out.shape}\")\n",
        "        print(f\"After LayerNorm2 values:\\n {out}\")\n",
        "\n",
        "        print(\"=================================\\n\")\n",
        "        return out\n",
        "\n",
        "    def qnn1():\n",
        "      feature_map = ZZFeatureMap(2)\n",
        "      ansatz = RealAmplitudes(2, reps=1)\n",
        "      qc = QuantumCircuit(2)\n",
        "      qc.compose(feature_map, inplace=True)\n",
        "      qc.compose(ansatz, inplace=True)\n",
        "\n",
        "      # Mengaktifkan input_gradients untuk backprop hybrid gradient\n",
        "      qnn = EstimatorQNN(\n",
        "          circuit=qc,\n",
        "          input_params=feature_map.parameters,\n",
        "          weight_params=ansatz.parameters,\n",
        "          input_gradients=True,\n",
        "          estimator=estimator,\n",
        "      )\n",
        "      return qnn\n",
        "\n",
        "class CustomGPT(nn.Module):\n",
        "    def __init__(self, vocab_size, embed_size, num_layers, heads, device, forward_expansion, dropout, max_length):\n",
        "        super(CustomGPT, self).__init__()\n",
        "        self.device = device\n",
        "        self.embed_size = embed_size\n",
        "        self.word_embedding = nn.Embedding(vocab_size, embed_size)\n",
        "        self.position_embedding = nn.Embedding(max_length, embed_size)\n",
        "        self.layers = nn.ModuleList([\n",
        "            GPTBlock(embed_size, heads, dropout, forward_expansion) for _ in range(num_layers)\n",
        "        ])\n",
        "        self.fc_out = nn.Linear(embed_size, vocab_size)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x, mask=None):\n",
        "        N, seq_length = x.shape\n",
        "        positions = torch.arange(0, seq_length, device=self.device).unsqueeze(0)\n",
        "        out = self.dropout(self.word_embedding(x) + self.position_embedding(positions))\n",
        "        for layer in self.layers:\n",
        "            out = layer(out, mask)\n",
        "        out = self.fc_out(out)\n",
        "        return out\n",
        "\n",
        "    def generate_text(self, input_ids, max_length):\n",
        "        self.eval()\n",
        "        for _ in range(max_length):\n",
        "            seq_length = input_ids.shape[1]\n",
        "            mask = causal_mask(seq_length, self.device)\n",
        "            logits = self.forward(input_ids, mask)\n",
        "            next_token = torch.argmax(logits[:, -1, :], dim=-1, keepdim=True)\n",
        "            input_ids = torch.cat([input_ids, next_token], dim=1)\n",
        "        return input_ids\n",
        "\n",
        "def causal_mask(seq_length, device):\n",
        "    \"\"\"Membuat causal mask dengan ukuran yang sesuai\"\"\"\n",
        "    mask = torch.tril(torch.ones((seq_length, seq_length), device=device))\n",
        "    return mask.masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Fixed QPT Model"
      ],
      "metadata": {
        "id": "u2IyZgtz-nfb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from qiskit import QuantumCircuit\n",
        "from qiskit.circuit.library import ZZFeatureMap, RealAmplitudes\n",
        "from qiskit_machine_learning.neural_networks import EstimatorQNN\n",
        "from qiskit.primitives import Estimator\n",
        "\n",
        "class QPTBlock(nn.Module):\n",
        "    def __init__(self, embed_size, heads, dropout, forward_expansion, reps=1):\n",
        "        super(QPTBlock, self).__init__()\n",
        "        self.attention = nn.MultiheadAttention(embed_dim=embed_size, num_heads=heads, batch_first=True)\n",
        "        self.norm1 = nn.LayerNorm(embed_size)\n",
        "        self.norm2 = nn.LayerNorm(embed_size)\n",
        "        self.norm3 = nn.LayerNorm(embed_size)\n",
        "        self.feed_forward = nn.Sequential(\n",
        "            nn.Linear(embed_size, forward_expansion * embed_size),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(forward_expansion * embed_size, embed_size)\n",
        "        )\n",
        "        self.reps = reps\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x, mask):\n",
        "        batch_size, seq_length, feature_dim = x.shape\n",
        "        attn_output, _ = self.attention(x, x, x, attn_mask=mask)\n",
        "        x = self.norm1(x + self.dropout(attn_output))\n",
        "        forward_out = self.feed_forward(x)\n",
        "        out = self.norm2(x + self.dropout(forward_out))\n",
        "        q_out = self.qnn1(x)\n",
        "        q_norm = self.norm2(x + self.dropout(q_out))\n",
        "        return q_norm\n",
        "\n",
        "    def qnn1(self, x):\n",
        "        batch_size, seq_length, feature_dim = x.shape\n",
        "        num_features = feature_dim\n",
        "        num_qubits = feature_dim\n",
        "        estimator = StatevectorEstimator()\n",
        "\n",
        "        feature_map = ZZFeatureMap(num_qubits)\n",
        "        ansatz = RealAmplitudes(num_qubits, reps=self.reps)\n",
        "\n",
        "        # Quantum Circuit\n",
        "        qc = QuantumCircuit(num_qubits)\n",
        "        qc.compose(feature_map, inplace=True)\n",
        "        qc.compose(ansatz, inplace=True)\n",
        "\n",
        "        # Definisi QNN\n",
        "        qnn = EstimatorQNN(\n",
        "            circuit=qc,\n",
        "            input_params=feature_map.parameters,\n",
        "            weight_params=ansatz.parameters,\n",
        "            input_gradients=True,\n",
        "            estimator=estimator,\n",
        "        )\n",
        "\n",
        "        # Menghubungkan dengan PyTorch menggunakan TorchConnector\n",
        "        qnn_layer = TorchConnector(qnn)\n",
        "\n",
        "        x = qnn_layer(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "class QPT(nn.Module):\n",
        "    def __init__(self, vocab_size, embed_size, num_layers, heads, device, forward_expansion, dropout, max_length):\n",
        "        super(QPT, self).__init__()\n",
        "        self.device = device\n",
        "        self.embed_size = embed_size\n",
        "        self.word_embedding = nn.Embedding(vocab_size, embed_size)\n",
        "        self.position_embedding = nn.Embedding(max_length, embed_size)\n",
        "        self.layers = nn.ModuleList([\n",
        "            QPTBlock(embed_size, heads, dropout, forward_expansion) for _ in range(num_layers)\n",
        "        ])\n",
        "        self.fc_out = nn.Linear(embed_size, vocab_size)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x, mask=None):\n",
        "        N, seq_length = x.shape\n",
        "        positions = torch.arange(0, seq_length, device=self.device).unsqueeze(0)\n",
        "        out = self.dropout(self.word_embedding(x) + self.position_embedding(positions))\n",
        "        for layer in self.layers:\n",
        "            out = layer(out, mask)\n",
        "        out = self.fc_out(out)\n",
        "        return out\n",
        "\n",
        "    def generate_text(self, input_ids, max_length):\n",
        "        self.eval()\n",
        "        for _ in range(max_length):\n",
        "            seq_length = input_ids.shape[1]\n",
        "            mask = causal_mask(seq_length, self.device)\n",
        "            logits = self.forward(input_ids, mask)\n",
        "            next_token = torch.argmax(logits[:, -1, :], dim=-1, keepdim=True)\n",
        "            input_ids = torch.cat([input_ids, next_token], dim=1)\n",
        "        return input_ids\n",
        "\n",
        "def causal_mask(seq_length, device):\n",
        "    \"\"\"Membuat causal mask dengan ukuran yang sesuai\"\"\"\n",
        "    mask = torch.tril(torch.ones((seq_length, seq_length), device=device))\n",
        "    return mask.masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))"
      ],
      "metadata": {
        "id": "UhNzfm6K6Paq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SimpleTokenizer:\n",
        "    def __init__(self, vocab):\n",
        "        self.vocab = {word: idx for idx, word in enumerate(vocab)}\n",
        "        self.inv_vocab = {idx: word for word, idx in self.vocab.items()}\n",
        "\n",
        "    def encode(self, text):\n",
        "        return torch.tensor([[self.vocab.get(word, self.vocab[\"<UNK>\"])] for word in text.split()], dtype=torch.long)\n",
        "\n",
        "    def decode(self, tokens):\n",
        "        return \" \".join([self.inv_vocab.get(int(token), \"<UNK>\") for token in tokens])"
      ],
      "metadata": {
        "id": "hX76p3o1zsu-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import Pipeline\n",
        "import torch\n",
        "\n",
        "class QPTPipeline(Pipeline):\n",
        "    def __init__(self, model, tokenizer, device=\"cpu\"):\n",
        "        self.model = model.to(device)\n",
        "        self.tokenizer = tokenizer\n",
        "        self.device = device\n",
        "\n",
        "    def _forward(self, inputs):\n",
        "        \"\"\"Proses forward dari pipeline.\"\"\"\n",
        "        tokens = self.tokenizer.encode(inputs)\n",
        "        tokens = tokens.to(self.device)\n",
        "        mask = causal_mask(tokens.shape[1], self.device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            output = self.model(tokens, mask)\n",
        "\n",
        "        output_tokens = torch.argmax(output, dim=-1).squeeze().tolist()\n",
        "        generated_text = self.tokenizer.decode(output_tokens)\n",
        "\n",
        "        return {\"generated_text\": generated_text}\n"
      ],
      "metadata": {
        "id": "0fQQ65BO-kLK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Buat vocab sederhana\n",
        "vocab = [\"hello\", \"world\", \"this\", \"is\", \"a\", \"test\", \"<PAD>\", \"<UNK>\"]\n",
        "tokenizer = SimpleTokenizer(vocab)\n",
        "\n",
        "# QPT\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "model = QPT(\n",
        "    vocab_size=len(vocab),\n",
        "    embed_size=16,\n",
        "    num_layers=2,\n",
        "    heads=2,\n",
        "    device=device,\n",
        "    forward_expansion=4,\n",
        "    dropout=0.1,\n",
        "    max_length=10\n",
        ").to(device)\n",
        "\n",
        "# Contoh input\n",
        "text = \"hello world\"\n",
        "input_ids = tokenizer.encode(text).T.to(device)\n",
        "\n",
        "# Generate teks baru\n",
        "generated_ids = model.generate_text(input_ids, max_length=5)\n",
        "generated_text = tokenizer.decode(generated_ids.squeeze(0).tolist())\n",
        "\n",
        "print(\"Generated Text:\", generated_text)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fpSdpxPQ8WBc",
        "outputId": "2b7834ac-367e-4321-f2f1-b994c6e822b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:qiskit_machine_learning.neural_networks.estimator_qnn:No gradient function provided, creating a gradient function. If your Estimator requires transpilation, please provide a pass manager.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "===== FORWARD PASS GPTBlock =====\n",
            "Input tensor shape: torch.Size([1, 2, 16])\n",
            "Attention output shape: torch.Size([1, 2, 16])\n",
            "Attention output values:\n",
            " tensor([[[-0.0173, -0.0520,  0.0578,  0.1463, -0.3406, -0.0839,  0.0198,\n",
            "           0.4546,  0.0734, -0.5396, -0.3322,  0.3096,  0.6608, -0.3068,\n",
            "           0.8802,  0.2424],\n",
            "         [-0.4089, -0.2677, -0.0553, -0.0294, -0.0931,  0.1733,  0.0309,\n",
            "           0.1977,  0.3444, -0.0926, -0.2511,  0.1161,  0.0842, -0.0959,\n",
            "           0.0996, -0.0221]]], grad_fn=<TransposeBackward0>)\n",
            "After LayerNorm1 shape: torch.Size([1, 2, 16])\n",
            "After LayerNorm1 values:\n",
            " tensor([[[-0.4416,  0.4411, -0.6206,  1.6393, -0.0280, -0.8981, -1.9141,\n",
            "           0.8860,  0.3474, -0.4151,  1.3381, -0.3884, -1.0729, -0.9800,\n",
            "           0.4546,  1.6520],\n",
            "         [-0.4905,  1.3870,  0.2051, -0.1102, -0.8697,  1.2020,  0.9405,\n",
            "          -0.3574, -1.0092,  0.0109, -0.5256, -1.8664,  2.0913,  0.7141,\n",
            "          -0.5338, -0.7881]]], grad_fn=<NativeLayerNormBackward0>)\n",
            "Feed Forward output shape: torch.Size([1, 2, 16])\n",
            "Feed Forward output values:\n",
            " tensor([[[ 0.0933, -0.2211,  0.1028, -0.2637, -0.2650, -0.0257, -0.1095,\n",
            "          -0.3201,  0.1263,  0.0211, -0.0018,  0.1233,  0.2637,  0.1207,\n",
            "          -0.0859, -0.2108],\n",
            "         [-0.0899,  0.1104, -0.4136,  0.1458,  0.0554,  0.1298,  0.0112,\n",
            "          -0.4353,  0.0701, -0.3547, -0.0633, -0.3523,  0.2012,  0.5396,\n",
            "          -0.1869, -0.1598]]], grad_fn=<ViewBackward0>)\n",
            "After LayerNorm2 shape: torch.Size([1, 2, 16])\n",
            "After LayerNorm2 values:\n",
            " tensor([[[-0.3348,  0.2840, -0.5192,  1.5420, -0.2746, -0.9613, -2.1586,\n",
            "           0.6605,  0.5601, -0.3845,  1.4993, -0.2442, -0.8365, -0.8911,\n",
            "           0.4458,  1.6134],\n",
            "         [-0.4627,  1.3480, -0.1386,  0.0741, -0.6665,  1.2037,  0.8725,\n",
            "          -0.6477, -0.7752, -0.2564, -0.4700, -1.8902,  2.0408,  1.1356,\n",
            "          -0.5848, -0.7828]]], grad_fn=<NativeLayerNormBackward0>)\n",
            "=================================\n",
            "\n",
            "\n",
            "===== FORWARD PASS GPTBlock =====\n",
            "Input tensor shape: torch.Size([1, 2, 16])\n",
            "Attention output shape: torch.Size([1, 2, 16])\n",
            "Attention output values:\n",
            " tensor([[[-0.9281, -0.6185, -0.6200,  0.0637,  0.2042,  0.7953,  0.4934,\n",
            "          -0.8538, -0.2729,  0.3200,  0.3530, -0.0619,  0.5641, -0.3844,\n",
            "           0.4562,  0.0455],\n",
            "         [ 0.0887, -0.4910, -0.3405,  0.2276, -0.0073,  0.4907,  0.1419,\n",
            "          -0.2056, -0.2369,  0.2991,  0.0270,  0.2408,  0.3458, -0.2494,\n",
            "          -0.1236,  0.4249]]], grad_fn=<TransposeBackward0>)\n",
            "After LayerNorm1 shape: torch.Size([1, 2, 16])\n",
            "After LayerNorm1 values:\n",
            " tensor([[[-1.2903, -0.1438, -1.1662,  1.6642,  0.1961, -0.0722, -1.3394,\n",
            "           0.0577,  0.0984, -0.0648,  1.6528, -0.4063, -0.4625, -1.2853,\n",
            "           0.9026,  1.6590],\n",
            "         [-0.4238,  0.8224, -0.1679,  0.0748, -0.8801,  1.5874,  1.0014,\n",
            "          -0.5786, -1.2344,  0.2598, -0.5167, -1.5988,  2.3021,  0.4082,\n",
            "          -0.6692, -0.3866]]], grad_fn=<NativeLayerNormBackward0>)\n",
            "Feed Forward output shape: torch.Size([1, 2, 16])\n",
            "Feed Forward output values:\n",
            " tensor([[[-0.1667,  0.4686, -0.1728, -0.2867, -0.2022,  0.5310,  0.0890,\n",
            "          -0.0121,  0.0117,  0.5684, -0.1856,  0.4342, -0.1431, -0.3381,\n",
            "          -0.0757, -0.6514],\n",
            "         [-0.1412, -0.0180,  0.0805, -0.1747,  0.1274,  0.0470, -0.0297,\n",
            "           0.2388, -0.1031,  0.0735,  0.1263,  0.0625,  0.3375, -0.0693,\n",
            "           0.1921,  0.0871]]], grad_fn=<ViewBackward0>)\n",
            "After LayerNorm2 shape: torch.Size([1, 2, 16])\n",
            "After LayerNorm2 values:\n",
            " tensor([[[-1.5057e+00,  3.4606e-01, -1.3831e+00,  1.4401e+00,  2.1758e-03,\n",
            "           4.8535e-01, -1.2909e+00,  5.5899e-02,  1.2292e-01,  5.3189e-01,\n",
            "           1.5334e+00,  3.7517e-02, -6.2077e-01, -1.6785e+00,  8.6787e-01,\n",
            "           1.0557e+00],\n",
            "         [-5.9795e-01,  7.2860e-01, -1.3537e-01, -1.4744e-01, -7.7979e-01,\n",
            "           1.5326e+00,  8.9070e-01, -3.7980e-01, -1.3464e+00,  2.7221e-01,\n",
            "          -4.2883e-01, -1.5389e+00,  2.5063e+00,  2.7769e-01, -5.1277e-01,\n",
            "          -3.4086e-01]]], grad_fn=<NativeLayerNormBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:qiskit_machine_learning.neural_networks.estimator_qnn:No gradient function provided, creating a gradient function. If your Estimator requires transpilation, please provide a pass manager.\n",
            "WARNING:qiskit_machine_learning.neural_networks.estimator_qnn:No gradient function provided, creating a gradient function. If your Estimator requires transpilation, please provide a pass manager.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=================================\n",
            "\n",
            "\n",
            "===== FORWARD PASS GPTBlock =====\n",
            "Input tensor shape: torch.Size([1, 3, 16])\n",
            "Attention output shape: torch.Size([1, 3, 16])\n",
            "Attention output values:\n",
            " tensor([[[-0.0173, -0.0520,  0.0578,  0.1463, -0.3406, -0.0839,  0.0198,\n",
            "           0.4546,  0.0734, -0.5396, -0.3322,  0.3096,  0.6608, -0.3068,\n",
            "           0.8802,  0.2424],\n",
            "         [-0.4089, -0.2677, -0.0553, -0.0294, -0.0931,  0.1733,  0.0309,\n",
            "           0.1977,  0.3444, -0.0926, -0.2511,  0.1161,  0.0842, -0.0959,\n",
            "           0.0996, -0.0221],\n",
            "         [-0.6048,  0.3803,  0.5669,  0.3687,  0.1840,  0.4337,  0.3551,\n",
            "           0.2703, -0.2131,  0.0049, -0.0772, -0.1377,  0.0443, -0.2824,\n",
            "          -0.2769,  0.5257]]], grad_fn=<TransposeBackward0>)\n",
            "After LayerNorm1 shape: torch.Size([1, 3, 16])\n",
            "After LayerNorm1 values:\n",
            " tensor([[[-0.4416,  0.4411, -0.6206,  1.6393, -0.0280, -0.8981, -1.9141,\n",
            "           0.8860,  0.3474, -0.4151,  1.3381, -0.3884, -1.0729, -0.9800,\n",
            "           0.4546,  1.6520],\n",
            "         [-0.4905,  1.3870,  0.2051, -0.1102, -0.8697,  1.2020,  0.9405,\n",
            "          -0.3574, -1.0092,  0.0109, -0.5256, -1.8664,  2.0913,  0.7141,\n",
            "          -0.5338, -0.7881],\n",
            "         [-1.0364,  0.7649,  0.4533,  0.1948, -1.2516,  0.3188,  0.2754,\n",
            "          -0.0783,  0.8065,  0.0832, -1.9033,  0.5634, -0.3755, -1.6734,\n",
            "           2.0306,  0.8277]]], grad_fn=<NativeLayerNormBackward0>)\n",
            "Feed Forward output shape: torch.Size([1, 3, 16])\n",
            "Feed Forward output values:\n",
            " tensor([[[ 0.0933, -0.2211,  0.1028, -0.2637, -0.2650, -0.0257, -0.1095,\n",
            "          -0.3201,  0.1263,  0.0211, -0.0018,  0.1233,  0.2637,  0.1207,\n",
            "          -0.0859, -0.2108],\n",
            "         [-0.0899,  0.1104, -0.4136,  0.1458,  0.0554,  0.1298,  0.0112,\n",
            "          -0.4353,  0.0701, -0.3547, -0.0633, -0.3523,  0.2012,  0.5396,\n",
            "          -0.1869, -0.1598],\n",
            "         [-0.3242,  0.1524,  0.2853, -0.0943, -0.1686,  0.0415, -0.1210,\n",
            "          -0.1273,  0.2592, -0.2948,  0.0879,  0.0743,  0.3226, -0.1960,\n",
            "          -0.1287, -0.3637]]], grad_fn=<ViewBackward0>)\n",
            "After LayerNorm2 shape: torch.Size([1, 3, 16])\n",
            "After LayerNorm2 values:\n",
            " tensor([[[-0.3348,  0.2840, -0.5192,  1.5420, -0.2746, -0.9613, -2.1586,\n",
            "           0.6605,  0.5601, -0.3845,  1.4993, -0.2442, -0.8365, -0.8911,\n",
            "           0.4458,  1.6134],\n",
            "         [-0.4627,  1.3480, -0.1386,  0.0741, -0.6665,  1.2037,  0.8725,\n",
            "          -0.6477, -0.7752, -0.2564, -0.4700, -1.8902,  2.0408,  1.1356,\n",
            "          -0.5848, -0.7828],\n",
            "         [-1.2600,  0.9087,  0.7386,  0.1311, -1.3167,  0.3785,  0.1825,\n",
            "          -0.1603,  1.0501, -0.1660, -1.6929,  0.6426, -0.0150, -1.7444,\n",
            "           1.8461,  0.4771]]], grad_fn=<NativeLayerNormBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:qiskit_machine_learning.neural_networks.estimator_qnn:No gradient function provided, creating a gradient function. If your Estimator requires transpilation, please provide a pass manager.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=================================\n",
            "\n",
            "\n",
            "===== FORWARD PASS GPTBlock =====\n",
            "Input tensor shape: torch.Size([1, 3, 16])\n",
            "Attention output shape: torch.Size([1, 3, 16])\n",
            "Attention output values:\n",
            " tensor([[[-0.9281, -0.6185, -0.6200,  0.0637,  0.2042,  0.7953,  0.4934,\n",
            "          -0.8538, -0.2729,  0.3200,  0.3530, -0.0619,  0.5641, -0.3844,\n",
            "           0.4562,  0.0455],\n",
            "         [ 0.0887, -0.4910, -0.3405,  0.2276, -0.0073,  0.4907,  0.1419,\n",
            "          -0.2056, -0.2369,  0.2991,  0.0270,  0.2408,  0.3458, -0.2494,\n",
            "          -0.1236,  0.4249],\n",
            "         [ 0.2936, -0.1846, -0.1150,  0.0176,  0.2602, -0.0943, -0.0831,\n",
            "          -0.1513, -0.2719,  0.2654, -0.0218,  0.2148, -0.1572,  0.0498,\n",
            "          -0.2274,  0.2091]]], grad_fn=<TransposeBackward0>)\n",
            "After LayerNorm1 shape: torch.Size([1, 3, 16])\n",
            "After LayerNorm1 values:\n",
            " tensor([[[-1.2903, -0.1438, -1.1662,  1.6642,  0.1961, -0.0722, -1.3394,\n",
            "           0.0577,  0.0984, -0.0648,  1.6528, -0.4063, -0.4625, -1.2853,\n",
            "           0.9026,  1.6590],\n",
            "         [-0.4238,  0.8224, -0.1679,  0.0748, -0.8801,  1.5874,  1.0014,\n",
            "          -0.5786, -1.2344,  0.2598, -0.5167, -1.5988,  2.3021,  0.4082,\n",
            "          -0.6692, -0.3866],\n",
            "         [-0.7905,  0.6171,  0.3597,  0.2257, -1.0550,  0.2386,  0.2044,\n",
            "          -0.2446,  0.5686,  0.3706, -2.0483,  0.8276, -0.5670, -1.7275,\n",
            "           1.9181,  1.1027]]], grad_fn=<NativeLayerNormBackward0>)\n",
            "Feed Forward output shape: torch.Size([1, 3, 16])\n",
            "Feed Forward output values:\n",
            " tensor([[[-0.1667,  0.4686, -0.1728, -0.2867, -0.2022,  0.5310,  0.0890,\n",
            "          -0.0121,  0.0117,  0.5684, -0.1856,  0.4342, -0.1431, -0.3381,\n",
            "          -0.0757, -0.6514],\n",
            "         [-0.1412, -0.0180,  0.0805, -0.1747,  0.1274,  0.0470, -0.0297,\n",
            "           0.2388, -0.1031,  0.0735,  0.1263,  0.0625,  0.3375, -0.0693,\n",
            "           0.1921,  0.0871],\n",
            "         [-0.3827,  0.6018, -0.5473, -0.0308,  0.0788,  0.3730,  0.3575,\n",
            "          -0.0206, -0.2453,  0.3565, -0.0851,  0.4335,  0.1533, -0.2898,\n",
            "           0.0803, -0.2172]]], grad_fn=<ViewBackward0>)\n",
            "After LayerNorm2 shape: torch.Size([1, 3, 16])\n",
            "After LayerNorm2 values:\n",
            " tensor([[[-1.5057e+00,  3.4606e-01, -1.3831e+00,  1.4401e+00,  2.1756e-03,\n",
            "           4.8535e-01, -1.2909e+00,  5.5899e-02,  1.2292e-01,  5.3189e-01,\n",
            "           1.5334e+00,  3.7517e-02, -6.2077e-01, -1.6785e+00,  8.6787e-01,\n",
            "           1.0557e+00],\n",
            "         [-5.9795e-01,  7.2860e-01, -1.3537e-01, -1.4744e-01, -7.7979e-01,\n",
            "           1.5326e+00,  8.9070e-01, -3.7980e-01, -1.3464e+00,  2.7221e-01,\n",
            "          -4.2882e-01, -1.5389e+00,  2.5063e+00,  2.7769e-01, -5.1277e-01,\n",
            "          -3.4086e-01],\n",
            "         [-1.0727e+00,  1.0449e+00, -2.0015e-01,  1.3850e-01, -8.9822e-01,\n",
            "           5.0731e-01,  4.6330e-01, -2.6883e-01,  2.5203e-01,  6.0960e-01,\n",
            "          -1.9227e+00,  1.0823e+00, -4.0030e-01, -1.8198e+00,  1.7349e+00,\n",
            "           7.4979e-01]]], grad_fn=<NativeLayerNormBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:qiskit_machine_learning.neural_networks.estimator_qnn:No gradient function provided, creating a gradient function. If your Estimator requires transpilation, please provide a pass manager.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=================================\n",
            "\n",
            "\n",
            "===== FORWARD PASS GPTBlock =====\n",
            "Input tensor shape: torch.Size([1, 4, 16])\n",
            "Attention output shape: torch.Size([1, 4, 16])\n",
            "Attention output values:\n",
            " tensor([[[-0.0173, -0.0520,  0.0578,  0.1463, -0.3406, -0.0839,  0.0198,\n",
            "           0.4546,  0.0734, -0.5396, -0.3322,  0.3096,  0.6608, -0.3068,\n",
            "           0.8802,  0.2424],\n",
            "         [-0.4089, -0.2677, -0.0553, -0.0294, -0.0931,  0.1733,  0.0309,\n",
            "           0.1977,  0.3444, -0.0926, -0.2511,  0.1161,  0.0842, -0.0959,\n",
            "           0.0996, -0.0221],\n",
            "         [-0.6048,  0.3803,  0.5669,  0.3687,  0.1840,  0.4337,  0.3551,\n",
            "           0.2703, -0.2130,  0.0049, -0.0772, -0.1377,  0.0443, -0.2824,\n",
            "          -0.2769,  0.5257],\n",
            "         [-0.0878,  0.4524,  0.3639,  0.3821,  0.2771, -0.1935,  0.1082,\n",
            "          -0.0107, -0.4040, -0.0544, -0.0787, -0.1890,  0.3107, -0.3292,\n",
            "           0.2937,  0.6249]]], grad_fn=<TransposeBackward0>)\n",
            "After LayerNorm1 shape: torch.Size([1, 4, 16])\n",
            "After LayerNorm1 values:\n",
            " tensor([[[-0.4416,  0.4411, -0.6206,  1.6393, -0.0280, -0.8981, -1.9141,\n",
            "           0.8860,  0.3474, -0.4151,  1.3381, -0.3884, -1.0729, -0.9800,\n",
            "           0.4546,  1.6520],\n",
            "         [-0.4905,  1.3870,  0.2051, -0.1102, -0.8697,  1.2020,  0.9405,\n",
            "          -0.3574, -1.0092,  0.0109, -0.5256, -1.8664,  2.0913,  0.7141,\n",
            "          -0.5338, -0.7881],\n",
            "         [-1.0364,  0.7649,  0.4533,  0.1948, -1.2516,  0.3188,  0.2754,\n",
            "          -0.0783,  0.8065,  0.0832, -1.9033,  0.5634, -0.3755, -1.6734,\n",
            "           2.0306,  0.8277],\n",
            "         [ 0.5900,  1.3484, -0.3079, -0.6792,  0.8298,  0.3355, -0.1004,\n",
            "           0.0414,  0.7585, -0.3123, -1.1621, -0.8110, -1.4009, -1.4685,\n",
            "           2.3796, -0.0409]]], grad_fn=<NativeLayerNormBackward0>)\n",
            "Feed Forward output shape: torch.Size([1, 4, 16])\n",
            "Feed Forward output values:\n",
            " tensor([[[ 0.0933, -0.2211,  0.1028, -0.2637, -0.2650, -0.0257, -0.1095,\n",
            "          -0.3201,  0.1263,  0.0211, -0.0018,  0.1233,  0.2637,  0.1207,\n",
            "          -0.0859, -0.2108],\n",
            "         [-0.0899,  0.1104, -0.4136,  0.1458,  0.0554,  0.1298,  0.0112,\n",
            "          -0.4353,  0.0701, -0.3547, -0.0633, -0.3523,  0.2012,  0.5396,\n",
            "          -0.1869, -0.1598],\n",
            "         [-0.3242,  0.1524,  0.2853, -0.0943, -0.1686,  0.0415, -0.1210,\n",
            "          -0.1273,  0.2592, -0.2948,  0.0879,  0.0743,  0.3226, -0.1960,\n",
            "          -0.1287, -0.3637],\n",
            "         [-0.2791,  0.1741,  0.0235,  0.0325, -0.1761,  0.1957, -0.2143,\n",
            "          -0.1649,  0.1965, -0.0191, -0.0789,  0.2894,  0.0643,  0.1802,\n",
            "           0.0098, -0.5350]]], grad_fn=<ViewBackward0>)\n",
            "After LayerNorm2 shape: torch.Size([1, 4, 16])\n",
            "After LayerNorm2 values:\n",
            " tensor([[[-0.3348,  0.2840, -0.5192,  1.5420, -0.2746, -0.9613, -2.1586,\n",
            "           0.6605,  0.5601, -0.3845,  1.4993, -0.2442, -0.8365, -0.8911,\n",
            "           0.4458,  1.6134],\n",
            "         [-0.4627,  1.3480, -0.1386,  0.0741, -0.6665,  1.2037,  0.8725,\n",
            "          -0.6477, -0.7752, -0.2564, -0.4700, -1.8902,  2.0408,  1.1356,\n",
            "          -0.5848, -0.7828],\n",
            "         [-1.2600,  0.9087,  0.7386,  0.1311, -1.3167,  0.3785,  0.1825,\n",
            "          -0.1603,  1.0501, -0.1660, -1.6929,  0.6426, -0.0150, -1.7444,\n",
            "           1.8461,  0.4771],\n",
            "         [ 0.3292,  1.5387, -0.2651, -0.6268,  0.6714,  0.5491, -0.2953,\n",
            "          -0.1046,  0.9723, -0.3120, -1.2202, -0.5019, -1.3156, -1.2674,\n",
            "           2.4043, -0.5561]]], grad_fn=<NativeLayerNormBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:qiskit_machine_learning.neural_networks.estimator_qnn:No gradient function provided, creating a gradient function. If your Estimator requires transpilation, please provide a pass manager.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=================================\n",
            "\n",
            "\n",
            "===== FORWARD PASS GPTBlock =====\n",
            "Input tensor shape: torch.Size([1, 4, 16])\n",
            "Attention output shape: torch.Size([1, 4, 16])\n",
            "Attention output values:\n",
            " tensor([[[-0.9281, -0.6185, -0.6200,  0.0637,  0.2042,  0.7953,  0.4934,\n",
            "          -0.8538, -0.2729,  0.3200,  0.3530, -0.0619,  0.5641, -0.3844,\n",
            "           0.4562,  0.0455],\n",
            "         [ 0.0887, -0.4910, -0.3405,  0.2276, -0.0073,  0.4907,  0.1419,\n",
            "          -0.2056, -0.2369,  0.2991,  0.0270,  0.2408,  0.3458, -0.2494,\n",
            "          -0.1236,  0.4249],\n",
            "         [ 0.2936, -0.1846, -0.1150,  0.0176,  0.2602, -0.0943, -0.0831,\n",
            "          -0.1513, -0.2719,  0.2654, -0.0218,  0.2148, -0.1572,  0.0498,\n",
            "          -0.2274,  0.2091],\n",
            "         [-0.2837, -0.0567, -0.2609, -0.1931,  0.3167, -0.1006, -0.0679,\n",
            "          -0.3130, -0.2458,  0.1872,  0.2087,  0.0036, -0.3275,  0.2212,\n",
            "           0.0785, -0.0915]]], grad_fn=<TransposeBackward0>)\n",
            "After LayerNorm1 shape: torch.Size([1, 4, 16])\n",
            "After LayerNorm1 values:\n",
            " tensor([[[-1.2903, -0.1438, -1.1662,  1.6642,  0.1961, -0.0722, -1.3394,\n",
            "           0.0577,  0.0984, -0.0648,  1.6528, -0.4063, -0.4625, -1.2853,\n",
            "           0.9026,  1.6590],\n",
            "         [-0.4238,  0.8224, -0.1679,  0.0748, -0.8801,  1.5874,  1.0014,\n",
            "          -0.5786, -1.2344,  0.2598, -0.5167, -1.5988,  2.3021,  0.4082,\n",
            "          -0.6692, -0.3866],\n",
            "         [-0.7905,  0.6171,  0.3597,  0.2257, -1.0550,  0.2386,  0.2044,\n",
            "          -0.2446,  0.5686,  0.3706, -2.0483,  0.8276, -0.5670, -1.7275,\n",
            "           1.9181,  1.1027],\n",
            "         [ 0.3563,  1.3206, -0.5001, -0.7971,  1.1785,  0.2863, -0.1081,\n",
            "          -0.2092,  0.5583, -0.0658, -0.8765, -0.7335, -1.6348, -1.1641,\n",
            "           2.4621, -0.0730]]], grad_fn=<NativeLayerNormBackward0>)\n",
            "Feed Forward output shape: torch.Size([1, 4, 16])\n",
            "Feed Forward output values:\n",
            " tensor([[[-0.1667,  0.4686, -0.1728, -0.2867, -0.2022,  0.5310,  0.0890,\n",
            "          -0.0121,  0.0117,  0.5684, -0.1856,  0.4342, -0.1431, -0.3381,\n",
            "          -0.0757, -0.6514],\n",
            "         [-0.1412, -0.0180,  0.0805, -0.1747,  0.1274,  0.0470, -0.0297,\n",
            "           0.2388, -0.1031,  0.0735,  0.1263,  0.0625,  0.3375, -0.0693,\n",
            "           0.1921,  0.0871],\n",
            "         [-0.3827,  0.6018, -0.5473, -0.0308,  0.0788,  0.3730,  0.3575,\n",
            "          -0.0206, -0.2453,  0.3565, -0.0851,  0.4335,  0.1533, -0.2898,\n",
            "           0.0803, -0.2172],\n",
            "         [-0.0116,  0.4095, -0.0588,  0.0487,  0.2026,  0.1394, -0.0593,\n",
            "           0.1268, -0.2372,  0.1609, -0.0964, -0.0542, -0.0192,  0.2732,\n",
            "           0.3072, -0.0428]]], grad_fn=<ViewBackward0>)\n",
            "After LayerNorm2 shape: torch.Size([1, 4, 16])\n",
            "After LayerNorm2 values:\n",
            " tensor([[[-1.5057e+00,  3.4606e-01, -1.3831e+00,  1.4401e+00,  2.1759e-03,\n",
            "           4.8535e-01, -1.2909e+00,  5.5899e-02,  1.2292e-01,  5.3189e-01,\n",
            "           1.5334e+00,  3.7517e-02, -6.2077e-01, -1.6785e+00,  8.6787e-01,\n",
            "           1.0557e+00],\n",
            "         [-5.9795e-01,  7.2860e-01, -1.3537e-01, -1.4744e-01, -7.7979e-01,\n",
            "           1.5326e+00,  8.9070e-01, -3.7980e-01, -1.3464e+00,  2.7221e-01,\n",
            "          -4.2882e-01, -1.5389e+00,  2.5063e+00,  2.7769e-01, -5.1277e-01,\n",
            "          -3.4086e-01],\n",
            "         [-1.0727e+00,  1.0449e+00, -2.0015e-01,  1.3850e-01, -8.9822e-01,\n",
            "           5.0731e-01,  4.6330e-01, -2.6883e-01,  2.5203e-01,  6.0960e-01,\n",
            "          -1.9227e+00,  1.0823e+00, -4.0030e-01, -1.8198e+00,  1.7349e+00,\n",
            "           7.4979e-01],\n",
            "         [ 2.5444e-01,  1.5282e+00, -5.7643e-01, -7.5072e-01,  1.2073e+00,\n",
            "           3.2890e-01, -2.1656e-01, -1.3842e-01,  2.3272e-01,  2.4832e-02,\n",
            "          -9.5709e-01, -7.8689e-01, -1.5834e+00, -8.8168e-01,  2.4837e+00,\n",
            "          -1.6900e-01]]], grad_fn=<NativeLayerNormBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:qiskit_machine_learning.neural_networks.estimator_qnn:No gradient function provided, creating a gradient function. If your Estimator requires transpilation, please provide a pass manager.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=================================\n",
            "\n",
            "\n",
            "===== FORWARD PASS GPTBlock =====\n",
            "Input tensor shape: torch.Size([1, 5, 16])\n",
            "Attention output shape: torch.Size([1, 5, 16])\n",
            "Attention output values:\n",
            " tensor([[[-0.0173, -0.0520,  0.0578,  0.1463, -0.3406, -0.0839,  0.0198,\n",
            "           0.4546,  0.0734, -0.5396, -0.3322,  0.3096,  0.6608, -0.3068,\n",
            "           0.8802,  0.2424],\n",
            "         [-0.4089, -0.2677, -0.0553, -0.0294, -0.0931,  0.1733,  0.0309,\n",
            "           0.1977,  0.3444, -0.0926, -0.2511,  0.1161,  0.0842, -0.0959,\n",
            "           0.0996, -0.0221],\n",
            "         [-0.6048,  0.3803,  0.5669,  0.3687,  0.1840,  0.4337,  0.3551,\n",
            "           0.2703, -0.2130,  0.0049, -0.0772, -0.1377,  0.0443, -0.2824,\n",
            "          -0.2769,  0.5257],\n",
            "         [-0.0878,  0.4524,  0.3639,  0.3821,  0.2771, -0.1935,  0.1082,\n",
            "          -0.0107, -0.4040, -0.0544, -0.0787, -0.1890,  0.3107, -0.3292,\n",
            "           0.2937,  0.6249],\n",
            "         [-0.0605,  0.1597,  0.2790,  0.1715,  0.0026,  0.0617,  0.0148,\n",
            "           0.2289, -0.1894, -0.1701, -0.0315, -0.0761,  0.2557, -0.2790,\n",
            "           0.2938,  0.3769]]], grad_fn=<TransposeBackward0>)\n",
            "After LayerNorm1 shape: torch.Size([1, 5, 16])\n",
            "After LayerNorm1 values:\n",
            " tensor([[[-0.4416,  0.4411, -0.6206,  1.6393, -0.0280, -0.8981, -1.9141,\n",
            "           0.8860,  0.3474, -0.4151,  1.3381, -0.3884, -1.0729, -0.9800,\n",
            "           0.4546,  1.6520],\n",
            "         [-0.4905,  1.3870,  0.2051, -0.1102, -0.8697,  1.2020,  0.9405,\n",
            "          -0.3574, -1.0092,  0.0109, -0.5256, -1.8664,  2.0913,  0.7141,\n",
            "          -0.5338, -0.7881],\n",
            "         [-1.0364,  0.7649,  0.4533,  0.1948, -1.2516,  0.3188,  0.2754,\n",
            "          -0.0783,  0.8065,  0.0832, -1.9033,  0.5634, -0.3755, -1.6734,\n",
            "           2.0306,  0.8277],\n",
            "         [ 0.5900,  1.3484, -0.3079, -0.6792,  0.8298,  0.3355, -0.1004,\n",
            "           0.0414,  0.7585, -0.3123, -1.1621, -0.8110, -1.4009, -1.4685,\n",
            "           2.3796, -0.0409],\n",
            "         [-0.6619,  0.5411,  1.6970, -0.7882,  1.1646, -1.4673, -0.5519,\n",
            "           0.5508, -0.3078,  0.7464, -2.2183,  0.8419, -0.5157, -0.4020,\n",
            "           0.6645,  0.7070]]], grad_fn=<NativeLayerNormBackward0>)\n",
            "Feed Forward output shape: torch.Size([1, 5, 16])\n",
            "Feed Forward output values:\n",
            " tensor([[[ 0.0933, -0.2211,  0.1028, -0.2637, -0.2650, -0.0257, -0.1095,\n",
            "          -0.3201,  0.1263,  0.0211, -0.0018,  0.1233,  0.2637,  0.1207,\n",
            "          -0.0859, -0.2108],\n",
            "         [-0.0899,  0.1104, -0.4136,  0.1458,  0.0554,  0.1298,  0.0112,\n",
            "          -0.4353,  0.0701, -0.3547, -0.0633, -0.3523,  0.2012,  0.5396,\n",
            "          -0.1869, -0.1598],\n",
            "         [-0.3242,  0.1524,  0.2853, -0.0943, -0.1686,  0.0415, -0.1210,\n",
            "          -0.1273,  0.2592, -0.2948,  0.0879,  0.0743,  0.3226, -0.1960,\n",
            "          -0.1287, -0.3637],\n",
            "         [-0.2791,  0.1741,  0.0235,  0.0325, -0.1761,  0.1957, -0.2143,\n",
            "          -0.1649,  0.1965, -0.0191, -0.0789,  0.2894,  0.0643,  0.1802,\n",
            "           0.0098, -0.5350],\n",
            "         [-0.1096,  0.3562,  0.5110, -0.0413,  0.0903, -0.0488, -0.2964,\n",
            "           0.1062, -0.0208, -0.0465, -0.1851, -0.1787,  0.5940,  0.0851,\n",
            "           0.1554, -0.4265]]], grad_fn=<ViewBackward0>)\n",
            "After LayerNorm2 shape: torch.Size([1, 5, 16])\n",
            "After LayerNorm2 values:\n",
            " tensor([[[-0.3348,  0.2840, -0.5192,  1.5420, -0.2746, -0.9613, -2.1586,\n",
            "           0.6605,  0.5601, -0.3845,  1.4993, -0.2442, -0.8365, -0.8911,\n",
            "           0.4458,  1.6134],\n",
            "         [-0.4627,  1.3480, -0.1386,  0.0741, -0.6665,  1.2037,  0.8725,\n",
            "          -0.6477, -0.7752, -0.2564, -0.4700, -1.8902,  2.0408,  1.1356,\n",
            "          -0.5848, -0.7828],\n",
            "         [-1.2600,  0.9087,  0.7386,  0.1311, -1.3167,  0.3785,  0.1825,\n",
            "          -0.1603,  1.0501, -0.1660, -1.6929,  0.6426, -0.0150, -1.7444,\n",
            "           1.8461,  0.4771],\n",
            "         [ 0.3292,  1.5387, -0.2651, -0.6268,  0.6714,  0.5491, -0.2953,\n",
            "          -0.1046,  0.9723, -0.3120, -1.2202, -0.5019, -1.3156, -1.2674,\n",
            "           2.4043, -0.5561],\n",
            "         [-0.7270,  0.7791,  1.9621, -0.7793,  1.1019, -1.3991, -0.7964,\n",
            "           0.5622, -0.3273,  0.6010, -2.2000,  0.5679,  0.0399, -0.3167,\n",
            "           0.7093,  0.2224]]], grad_fn=<NativeLayerNormBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:qiskit_machine_learning.neural_networks.estimator_qnn:No gradient function provided, creating a gradient function. If your Estimator requires transpilation, please provide a pass manager.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=================================\n",
            "\n",
            "\n",
            "===== FORWARD PASS GPTBlock =====\n",
            "Input tensor shape: torch.Size([1, 5, 16])\n",
            "Attention output shape: torch.Size([1, 5, 16])\n",
            "Attention output values:\n",
            " tensor([[[-0.9281, -0.6185, -0.6200,  0.0637,  0.2042,  0.7953,  0.4934,\n",
            "          -0.8538, -0.2729,  0.3200,  0.3530, -0.0619,  0.5641, -0.3844,\n",
            "           0.4562,  0.0455],\n",
            "         [ 0.0887, -0.4910, -0.3405,  0.2276, -0.0073,  0.4907,  0.1419,\n",
            "          -0.2056, -0.2369,  0.2991,  0.0270,  0.2408,  0.3458, -0.2494,\n",
            "          -0.1236,  0.4249],\n",
            "         [ 0.2936, -0.1846, -0.1150,  0.0176,  0.2602, -0.0943, -0.0831,\n",
            "          -0.1513, -0.2719,  0.2654, -0.0218,  0.2148, -0.1572,  0.0498,\n",
            "          -0.2274,  0.2091],\n",
            "         [-0.2837, -0.0567, -0.2609, -0.1931,  0.3167, -0.1006, -0.0679,\n",
            "          -0.3130, -0.2458,  0.1872,  0.2087,  0.0036, -0.3275,  0.2212,\n",
            "           0.0785, -0.0915],\n",
            "         [-0.2532, -0.0466, -0.2012, -0.1476,  0.3529, -0.2844, -0.0088,\n",
            "          -0.3296, -0.1927,  0.2130,  0.1163, -0.0104, -0.4294,  0.1886,\n",
            "           0.2783, -0.3415]]], grad_fn=<TransposeBackward0>)\n",
            "After LayerNorm1 shape: torch.Size([1, 5, 16])\n",
            "After LayerNorm1 values:\n",
            " tensor([[[-1.2903, -0.1438, -1.1662,  1.6642,  0.1961, -0.0722, -1.3394,\n",
            "           0.0577,  0.0984, -0.0648,  1.6528, -0.4063, -0.4625, -1.2853,\n",
            "           0.9026,  1.6590],\n",
            "         [-0.4238,  0.8224, -0.1679,  0.0748, -0.8801,  1.5874,  1.0014,\n",
            "          -0.5786, -1.2344,  0.2598, -0.5167, -1.5988,  2.3021,  0.4082,\n",
            "          -0.6692, -0.3866],\n",
            "         [-0.7905,  0.6171,  0.3597,  0.2257, -1.0550,  0.2386,  0.2044,\n",
            "          -0.2446,  0.5686,  0.3706, -2.0483,  0.8276, -0.5670, -1.7275,\n",
            "           1.9181,  1.1027],\n",
            "         [ 0.3563,  1.3206, -0.5001, -0.7971,  1.1785,  0.2863, -0.1081,\n",
            "          -0.2092,  0.5583, -0.0658, -0.8765, -0.7335, -1.6348, -1.1641,\n",
            "           2.4621, -0.0730],\n",
            "         [-0.7961,  0.5294,  1.4709, -0.8154,  1.4913, -1.5827, -0.4628,\n",
            "           0.2724, -0.4062,  0.9665, -1.9121,  0.8463, -0.8243, -0.1362,\n",
            "           0.9509,  0.4080]]], grad_fn=<NativeLayerNormBackward0>)\n",
            "Feed Forward output shape: torch.Size([1, 5, 16])\n",
            "Feed Forward output values:\n",
            " tensor([[[-0.1667,  0.4686, -0.1728, -0.2867, -0.2022,  0.5310,  0.0890,\n",
            "          -0.0121,  0.0117,  0.5684, -0.1856,  0.4342, -0.1431, -0.3381,\n",
            "          -0.0757, -0.6514],\n",
            "         [-0.1412, -0.0180,  0.0805, -0.1747,  0.1274,  0.0470, -0.0297,\n",
            "           0.2388, -0.1031,  0.0735,  0.1263,  0.0625,  0.3375, -0.0693,\n",
            "           0.1921,  0.0871],\n",
            "         [-0.3827,  0.6018, -0.5473, -0.0308,  0.0788,  0.3730,  0.3575,\n",
            "          -0.0206, -0.2453,  0.3565, -0.0851,  0.4335,  0.1533, -0.2898,\n",
            "           0.0803, -0.2172],\n",
            "         [-0.0116,  0.4095, -0.0588,  0.0487,  0.2026,  0.1394, -0.0593,\n",
            "           0.1268, -0.2372,  0.1609, -0.0964, -0.0542, -0.0192,  0.2732,\n",
            "           0.3072, -0.0428],\n",
            "         [ 0.1621,  0.4220, -0.0638,  0.1189,  0.0187,  0.1616, -0.1107,\n",
            "           0.1341, -0.2014,  0.4940, -0.0072,  0.1882,  0.2658,  0.0071,\n",
            "           0.4573, -0.0245]]], grad_fn=<ViewBackward0>)\n",
            "After LayerNorm2 shape: torch.Size([1, 5, 16])\n",
            "After LayerNorm2 values:\n",
            " tensor([[[-1.5057e+00,  3.4606e-01, -1.3831e+00,  1.4401e+00,  2.1759e-03,\n",
            "           4.8535e-01, -1.2909e+00,  5.5899e-02,  1.2292e-01,  5.3189e-01,\n",
            "           1.5333e+00,  3.7517e-02, -6.2077e-01, -1.6785e+00,  8.6787e-01,\n",
            "           1.0557e+00],\n",
            "         [-5.9795e-01,  7.2860e-01, -1.3537e-01, -1.4744e-01, -7.7979e-01,\n",
            "           1.5326e+00,  8.9070e-01, -3.7980e-01, -1.3464e+00,  2.7221e-01,\n",
            "          -4.2883e-01, -1.5389e+00,  2.5063e+00,  2.7769e-01, -5.1277e-01,\n",
            "          -3.4086e-01],\n",
            "         [-1.0727e+00,  1.0449e+00, -2.0015e-01,  1.3850e-01, -8.9822e-01,\n",
            "           5.0731e-01,  4.6330e-01, -2.6883e-01,  2.5203e-01,  6.0960e-01,\n",
            "          -1.9227e+00,  1.0823e+00, -4.0030e-01, -1.8198e+00,  1.7349e+00,\n",
            "           7.4979e-01],\n",
            "         [ 2.5444e-01,  1.5282e+00, -5.7643e-01, -7.5072e-01,  1.2073e+00,\n",
            "           3.2890e-01, -2.1656e-01, -1.3842e-01,  2.3272e-01,  2.4832e-02,\n",
            "          -9.5709e-01, -7.8689e-01, -1.5834e+00, -8.8168e-01,  2.4837e+00,\n",
            "          -1.6900e-01],\n",
            "         [-7.1633e-01,  7.7725e-01,  1.2066e+00, -7.7532e-01,  1.3035e+00,\n",
            "          -1.4580e+00, -6.5938e-01,  2.6390e-01, -6.9150e-01,  1.2570e+00,\n",
            "          -1.9274e+00,  8.5558e-01, -6.4525e-01, -2.4070e-01,  1.2077e+00,\n",
            "           2.4227e-01]]], grad_fn=<NativeLayerNormBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:qiskit_machine_learning.neural_networks.estimator_qnn:No gradient function provided, creating a gradient function. If your Estimator requires transpilation, please provide a pass manager.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=================================\n",
            "\n",
            "\n",
            "===== FORWARD PASS GPTBlock =====\n",
            "Input tensor shape: torch.Size([1, 6, 16])\n",
            "Attention output shape: torch.Size([1, 6, 16])\n",
            "Attention output values:\n",
            " tensor([[[-0.0173, -0.0520,  0.0578,  0.1463, -0.3406, -0.0839,  0.0198,\n",
            "           0.4546,  0.0734, -0.5396, -0.3322,  0.3096,  0.6608, -0.3068,\n",
            "           0.8802,  0.2424],\n",
            "         [-0.4089, -0.2677, -0.0553, -0.0294, -0.0931,  0.1733,  0.0309,\n",
            "           0.1977,  0.3444, -0.0926, -0.2511,  0.1161,  0.0842, -0.0959,\n",
            "           0.0996, -0.0221],\n",
            "         [-0.6048,  0.3803,  0.5669,  0.3687,  0.1840,  0.4337,  0.3551,\n",
            "           0.2703, -0.2130,  0.0049, -0.0772, -0.1377,  0.0443, -0.2824,\n",
            "          -0.2769,  0.5257],\n",
            "         [-0.0878,  0.4524,  0.3639,  0.3821,  0.2771, -0.1935,  0.1082,\n",
            "          -0.0107, -0.4040, -0.0544, -0.0787, -0.1890,  0.3107, -0.3292,\n",
            "           0.2937,  0.6249],\n",
            "         [-0.0605,  0.1597,  0.2790,  0.1715,  0.0026,  0.0617,  0.0148,\n",
            "           0.2289, -0.1894, -0.1701, -0.0315, -0.0761,  0.2557, -0.2790,\n",
            "           0.2938,  0.3769],\n",
            "         [ 0.3289,  0.0334,  0.0474,  0.0488,  0.0206, -0.2892, -0.1448,\n",
            "           0.0293, -0.2936, -0.2763, -0.0380,  0.1412,  0.3662, -0.1561,\n",
            "           0.4923,  0.4241]]], grad_fn=<TransposeBackward0>)\n",
            "After LayerNorm1 shape: torch.Size([1, 6, 16])\n",
            "After LayerNorm1 values:\n",
            " tensor([[[-0.4416,  0.4411, -0.6206,  1.6393, -0.0280, -0.8981, -1.9141,\n",
            "           0.8860,  0.3474, -0.4151,  1.3381, -0.3884, -1.0729, -0.9800,\n",
            "           0.4546,  1.6520],\n",
            "         [-0.4905,  1.3870,  0.2051, -0.1102, -0.8697,  1.2020,  0.9405,\n",
            "          -0.3574, -1.0092,  0.0109, -0.5256, -1.8664,  2.0913,  0.7141,\n",
            "          -0.5338, -0.7881],\n",
            "         [-1.0364,  0.7649,  0.4533,  0.1948, -1.2516,  0.3188,  0.2754,\n",
            "          -0.0783,  0.8065,  0.0832, -1.9033,  0.5634, -0.3755, -1.6734,\n",
            "           2.0306,  0.8277],\n",
            "         [ 0.5900,  1.3484, -0.3079, -0.6792,  0.8298,  0.3355, -0.1004,\n",
            "           0.0414,  0.7585, -0.3123, -1.1621, -0.8110, -1.4009, -1.4685,\n",
            "           2.3796, -0.0409],\n",
            "         [-0.6619,  0.5411,  1.6970, -0.7882,  1.1646, -1.4673, -0.5519,\n",
            "           0.5508, -0.3078,  0.7464, -2.2183,  0.8419, -0.5157, -0.4020,\n",
            "           0.6645,  0.7070],\n",
            "         [-0.3033,  0.3651,  1.4471, -0.4771,  2.1559, -0.9951, -1.6946,\n",
            "           0.7538, -0.9919, -0.9330,  0.3368, -0.8365, -0.0037, -0.2680,\n",
            "           0.1779,  1.2665]]], grad_fn=<NativeLayerNormBackward0>)\n",
            "Feed Forward output shape: torch.Size([1, 6, 16])\n",
            "Feed Forward output values:\n",
            " tensor([[[ 0.0933, -0.2211,  0.1028, -0.2637, -0.2650, -0.0257, -0.1095,\n",
            "          -0.3201,  0.1263,  0.0211, -0.0018,  0.1233,  0.2637,  0.1207,\n",
            "          -0.0859, -0.2108],\n",
            "         [-0.0899,  0.1104, -0.4136,  0.1458,  0.0554,  0.1298,  0.0112,\n",
            "          -0.4353,  0.0701, -0.3547, -0.0633, -0.3523,  0.2012,  0.5396,\n",
            "          -0.1869, -0.1598],\n",
            "         [-0.3242,  0.1524,  0.2853, -0.0943, -0.1686,  0.0415, -0.1210,\n",
            "          -0.1273,  0.2592, -0.2948,  0.0879,  0.0743,  0.3226, -0.1960,\n",
            "          -0.1287, -0.3637],\n",
            "         [-0.2791,  0.1741,  0.0235,  0.0325, -0.1761,  0.1957, -0.2143,\n",
            "          -0.1649,  0.1965, -0.0191, -0.0789,  0.2894,  0.0643,  0.1802,\n",
            "           0.0098, -0.5350],\n",
            "         [-0.1096,  0.3562,  0.5110, -0.0413,  0.0903, -0.0488, -0.2964,\n",
            "           0.1062, -0.0208, -0.0465, -0.1851, -0.1787,  0.5940,  0.0851,\n",
            "           0.1554, -0.4265],\n",
            "         [-0.0103, -0.1517,  0.1451, -0.0061, -0.1333,  0.1872, -0.1696,\n",
            "          -0.4892, -0.1518,  0.3193, -0.1762,  0.1080,  0.2964,  0.2751,\n",
            "          -0.0934, -0.2088]]], grad_fn=<ViewBackward0>)\n",
            "After LayerNorm2 shape: torch.Size([1, 6, 16])\n",
            "After LayerNorm2 values:\n",
            " tensor([[[-0.3348,  0.2840, -0.5192,  1.5420, -0.2746, -0.9613, -2.1586,\n",
            "           0.6605,  0.5601, -0.3845,  1.4993, -0.2442, -0.8365, -0.8911,\n",
            "           0.4458,  1.6134],\n",
            "         [-0.4627,  1.3480, -0.1386,  0.0741, -0.6665,  1.2037,  0.8725,\n",
            "          -0.6477, -0.7752, -0.2564, -0.4700, -1.8902,  2.0408,  1.1356,\n",
            "          -0.5848, -0.7828],\n",
            "         [-1.2600,  0.9087,  0.7386,  0.1311, -1.3167,  0.3785,  0.1825,\n",
            "          -0.1603,  1.0501, -0.1660, -1.6929,  0.6426, -0.0150, -1.7444,\n",
            "           1.8461,  0.4771],\n",
            "         [ 0.3292,  1.5387, -0.2651, -0.6268,  0.6714,  0.5491, -0.2953,\n",
            "          -0.1046,  0.9723, -0.3120, -1.2202, -0.5019, -1.3156, -1.2674,\n",
            "           2.4043, -0.5561],\n",
            "         [-0.7270,  0.7791,  1.9621, -0.7793,  1.1019, -1.3991, -0.7964,\n",
            "           0.5622, -0.3273,  0.6010, -2.2000,  0.5679,  0.0399, -0.3167,\n",
            "           0.7093,  0.2224],\n",
            "         [-0.3107,  0.2400,  1.6808, -0.4880,  2.1307, -0.8274, -1.9313,\n",
            "           0.2934, -1.1783, -0.6244,  0.1849, -0.7444,  0.3228,  0.0244,\n",
            "           0.1052,  1.1223]]], grad_fn=<NativeLayerNormBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:qiskit_machine_learning.neural_networks.estimator_qnn:No gradient function provided, creating a gradient function. If your Estimator requires transpilation, please provide a pass manager.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=================================\n",
            "\n",
            "\n",
            "===== FORWARD PASS GPTBlock =====\n",
            "Input tensor shape: torch.Size([1, 6, 16])\n",
            "Attention output shape: torch.Size([1, 6, 16])\n",
            "Attention output values:\n",
            " tensor([[[-0.9281, -0.6185, -0.6200,  0.0637,  0.2042,  0.7953,  0.4934,\n",
            "          -0.8538, -0.2729,  0.3200,  0.3530, -0.0619,  0.5641, -0.3844,\n",
            "           0.4562,  0.0455],\n",
            "         [ 0.0887, -0.4910, -0.3405,  0.2276, -0.0073,  0.4907,  0.1419,\n",
            "          -0.2056, -0.2369,  0.2991,  0.0270,  0.2408,  0.3458, -0.2494,\n",
            "          -0.1236,  0.4249],\n",
            "         [ 0.2936, -0.1846, -0.1150,  0.0176,  0.2602, -0.0943, -0.0831,\n",
            "          -0.1513, -0.2719,  0.2654, -0.0218,  0.2148, -0.1572,  0.0498,\n",
            "          -0.2274,  0.2091],\n",
            "         [-0.2837, -0.0567, -0.2609, -0.1931,  0.3167, -0.1006, -0.0679,\n",
            "          -0.3130, -0.2458,  0.1872,  0.2087,  0.0036, -0.3275,  0.2212,\n",
            "           0.0785, -0.0915],\n",
            "         [-0.2532, -0.0466, -0.2012, -0.1476,  0.3529, -0.2844, -0.0088,\n",
            "          -0.3296, -0.1927,  0.2130,  0.1163, -0.0104, -0.4294,  0.1886,\n",
            "           0.2783, -0.3415],\n",
            "         [-0.2816, -0.0818, -0.3176, -0.1022,  0.2760, -0.1219,  0.0213,\n",
            "          -0.2676, -0.2220,  0.2794,  0.0809,  0.0235, -0.3032,  0.0683,\n",
            "           0.4132, -0.3788]]], grad_fn=<TransposeBackward0>)\n",
            "After LayerNorm1 shape: torch.Size([1, 6, 16])\n",
            "After LayerNorm1 values:\n",
            " tensor([[[-1.2903, -0.1438, -1.1662,  1.6642,  0.1961, -0.0722, -1.3394,\n",
            "           0.0577,  0.0984, -0.0648,  1.6528, -0.4063, -0.4625, -1.2853,\n",
            "           0.9026,  1.6590],\n",
            "         [-0.4238,  0.8224, -0.1679,  0.0748, -0.8801,  1.5874,  1.0014,\n",
            "          -0.5786, -1.2344,  0.2598, -0.5167, -1.5988,  2.3021,  0.4082,\n",
            "          -0.6692, -0.3866],\n",
            "         [-0.7905,  0.6171,  0.3597,  0.2257, -1.0550,  0.2386,  0.2044,\n",
            "          -0.2446,  0.5686,  0.3706, -2.0483,  0.8276, -0.5670, -1.7275,\n",
            "           1.9181,  1.1027],\n",
            "         [ 0.3563,  1.3206, -0.5001, -0.7971,  1.1785,  0.2863, -0.1081,\n",
            "          -0.2092,  0.5583, -0.0658, -0.8765, -0.7335, -1.6348, -1.1641,\n",
            "           2.4621, -0.0730],\n",
            "         [-0.7961,  0.5294,  1.4709, -0.8154,  1.4913, -1.5827, -0.4628,\n",
            "           0.2724, -0.4062,  0.9665, -1.9121,  0.8463, -0.8243, -0.1362,\n",
            "           0.9509,  0.4080],\n",
            "         [-0.5247,  0.3385,  1.1797, -0.5191,  2.4746, -1.0537, -1.6068,\n",
            "           0.5401, -1.1501, -0.5929,  0.4721, -0.7515, -0.2483, -0.1417,\n",
            "           0.6444,  0.9394]]], grad_fn=<NativeLayerNormBackward0>)\n",
            "Feed Forward output shape: torch.Size([1, 6, 16])\n",
            "Feed Forward output values:\n",
            " tensor([[[-0.1667,  0.4686, -0.1728, -0.2867, -0.2022,  0.5310,  0.0890,\n",
            "          -0.0121,  0.0117,  0.5684, -0.1856,  0.4342, -0.1431, -0.3381,\n",
            "          -0.0757, -0.6514],\n",
            "         [-0.1412, -0.0180,  0.0805, -0.1747,  0.1274,  0.0470, -0.0297,\n",
            "           0.2388, -0.1031,  0.0735,  0.1263,  0.0625,  0.3375, -0.0693,\n",
            "           0.1921,  0.0871],\n",
            "         [-0.3827,  0.6018, -0.5473, -0.0308,  0.0788,  0.3730,  0.3575,\n",
            "          -0.0206, -0.2453,  0.3565, -0.0851,  0.4335,  0.1533, -0.2898,\n",
            "           0.0803, -0.2172],\n",
            "         [-0.0116,  0.4095, -0.0588,  0.0487,  0.2026,  0.1394, -0.0593,\n",
            "           0.1268, -0.2372,  0.1609, -0.0964, -0.0542, -0.0192,  0.2732,\n",
            "           0.3072, -0.0428],\n",
            "         [ 0.1621,  0.4220, -0.0638,  0.1189,  0.0187,  0.1616, -0.1107,\n",
            "           0.1341, -0.2014,  0.4940, -0.0072,  0.1882,  0.2658,  0.0071,\n",
            "           0.4573, -0.0245],\n",
            "         [ 0.2529,  0.5038,  0.1476,  0.0956,  0.2203,  0.1633, -0.2186,\n",
            "          -0.1043,  0.0746,  0.4847, -0.0179,  0.1746, -0.0034,  0.1084,\n",
            "           0.4283,  0.0412]]], grad_fn=<ViewBackward0>)\n",
            "After LayerNorm2 shape: torch.Size([1, 6, 16])\n",
            "After LayerNorm2 values:\n",
            " tensor([[[-1.5057e+00,  3.4606e-01, -1.3831e+00,  1.4401e+00,  2.1759e-03,\n",
            "           4.8535e-01, -1.2909e+00,  5.5899e-02,  1.2292e-01,  5.3189e-01,\n",
            "           1.5333e+00,  3.7517e-02, -6.2077e-01, -1.6785e+00,  8.6787e-01,\n",
            "           1.0557e+00],\n",
            "         [-5.9795e-01,  7.2860e-01, -1.3537e-01, -1.4744e-01, -7.7979e-01,\n",
            "           1.5326e+00,  8.9070e-01, -3.7980e-01, -1.3464e+00,  2.7221e-01,\n",
            "          -4.2883e-01, -1.5389e+00,  2.5063e+00,  2.7769e-01, -5.1277e-01,\n",
            "          -3.4086e-01],\n",
            "         [-1.0727e+00,  1.0449e+00, -2.0015e-01,  1.3850e-01, -8.9822e-01,\n",
            "           5.0731e-01,  4.6330e-01, -2.6883e-01,  2.5203e-01,  6.0960e-01,\n",
            "          -1.9227e+00,  1.0823e+00, -4.0030e-01, -1.8198e+00,  1.7349e+00,\n",
            "           7.4979e-01],\n",
            "         [ 2.5444e-01,  1.5282e+00, -5.7643e-01, -7.5072e-01,  1.2073e+00,\n",
            "           3.2890e-01, -2.1656e-01, -1.3842e-01,  2.3272e-01,  2.4832e-02,\n",
            "          -9.5709e-01, -7.8689e-01, -1.5834e+00, -8.8168e-01,  2.4837e+00,\n",
            "          -1.6900e-01],\n",
            "         [-7.1633e-01,  7.7725e-01,  1.2066e+00, -7.7532e-01,  1.3035e+00,\n",
            "          -1.4580e+00, -6.5938e-01,  2.6390e-01, -6.9150e-01,  1.2570e+00,\n",
            "          -1.9274e+00,  8.5558e-01, -6.4525e-01, -2.4070e-01,  1.2077e+00,\n",
            "           2.4227e-01],\n",
            "         [-3.9655e-01,  6.5849e-01,  1.1178e+00, -5.4017e-01,  2.4130e+00,\n",
            "          -9.8239e-01, -1.8678e+00,  2.7353e-01, -1.1576e+00, -2.4163e-01,\n",
            "           2.9095e-01, -6.8544e-01, -3.7755e-01, -1.7073e-01,  8.7673e-01,\n",
            "           7.8946e-01]]], grad_fn=<NativeLayerNormBackward0>)\n",
            "=================================\n",
            "\n",
            "Generated Text: hello world test <UNK> <PAD> is is\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Buat vocab sederhana\n",
        "vocab = [\"hello\", \"world\", \"this\", \"is\", \"a\", \"test\", \"<PAD>\", \"<UNK>\"]\n",
        "tokenizer = SimpleTokenizer(vocab)\n",
        "\n",
        "# Inisialisasi model\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "model = CustomGPT(\n",
        "    vocab_size=len(vocab),\n",
        "    embed_size=16,\n",
        "    num_layers=2,\n",
        "    heads=2,\n",
        "    device=device,\n",
        "    forward_expansion=4,\n",
        "    dropout=0.1,\n",
        "    max_length=10\n",
        ").to(device)\n",
        "\n",
        "# Contoh input\n",
        "text = \"hello world\"\n",
        "input_ids = tokenizer.encode(text).T.to(device)\n",
        "\n",
        "# Generate teks baru\n",
        "generated_ids = model.generate_text(input_ids, max_length=5)\n",
        "generated_text = tokenizer.decode(generated_ids.squeeze(0).tolist())\n",
        "\n",
        "print(\"Generated Text:\", generated_text)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kSzXIlI2zwW6",
        "outputId": "6fc0d0f7-225b-4eab-d10b-ff9ccda46a47"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "===== FORWARD PASS GPTBlock =====\n",
            "Input tensor shape: torch.Size([1, 2, 16])\n",
            "Attention output shape: torch.Size([1, 2, 16])\n",
            "Attention output values:\n",
            " tensor([[[ 0.4976, -0.0425, -0.6015, -0.8495,  1.3402, -0.0253, -0.6126,\n",
            "           0.2388,  0.5035, -0.1005,  0.5271,  0.4137,  0.6495,  0.3852,\n",
            "           0.3827,  0.7076],\n",
            "         [-0.1732,  0.2964,  0.4973, -0.1324,  0.7904,  0.1026, -0.2555,\n",
            "           0.3387, -0.3192, -0.3305, -0.3001,  0.0357,  0.8668, -0.2059,\n",
            "          -0.1829, -0.1117]]], grad_fn=<TransposeBackward0>)\n",
            "After LayerNorm1 shape: torch.Size([1, 2, 16])\n",
            "After LayerNorm1 values:\n",
            " tensor([[[ 0.2980, -0.1057, -2.5523, -0.7322, -0.2220, -0.7078, -0.1928,\n",
            "           0.9957,  1.1922,  0.4540,  1.5406, -0.0144,  0.2068,  1.2288,\n",
            "          -1.3077, -0.0813],\n",
            "         [-0.7321,  1.3929,  0.1498,  0.8795,  0.6939, -0.4162, -1.0340,\n",
            "          -0.4927, -1.8187, -0.1534, -1.4248,  2.0437, -0.2131, -0.2776,\n",
            "           0.4598,  0.9431]]], grad_fn=<NativeLayerNormBackward0>)\n",
            "Feed Forward output shape: torch.Size([1, 2, 16])\n",
            "Feed Forward output values:\n",
            " tensor([[[-0.3009,  0.0641, -0.5448, -0.2372,  0.1203, -0.1077,  0.3984,\n",
            "           0.2516,  0.2372,  0.0981,  0.2294, -0.2621,  0.5163,  0.0416,\n",
            "           0.0403, -0.2411],\n",
            "         [-0.1485,  0.2635,  0.1340,  0.0399, -0.1343,  0.0301,  0.0224,\n",
            "          -0.0624,  0.1660,  0.3150,  0.0520,  0.1765, -0.0031, -0.1932,\n",
            "          -0.4195, -0.1596]]], grad_fn=<ViewBackward0>)\n",
            "After LayerNorm2 shape: torch.Size([1, 2, 16])\n",
            "After LayerNorm2 values:\n",
            " tensor([[[-0.0186, -0.0514, -2.6451, -0.8389, -0.1024, -0.7083,  0.1584,\n",
            "           1.0427,  1.1972,  0.4526,  1.4864, -0.2508,  0.5977,  1.0623,\n",
            "          -1.0919, -0.2898],\n",
            "         [-0.8670,  1.6168,  0.2729,  0.8953,  0.5430, -0.3828, -0.9952,\n",
            "          -0.5483, -1.6229,  0.1534, -1.3488,  2.1688, -0.2165, -0.4657,\n",
            "           0.0347,  0.7622]]], grad_fn=<NativeLayerNormBackward0>)\n",
            "=================================\n",
            "\n",
            "\n",
            "===== FORWARD PASS GPTBlock =====\n",
            "Input tensor shape: torch.Size([1, 2, 16])\n",
            "Attention output shape: torch.Size([1, 2, 16])\n",
            "Attention output values:\n",
            " tensor([[[-0.6057, -0.4886, -0.1524, -0.3819, -0.0107, -0.3277, -0.0704,\n",
            "           0.2727,  0.1893, -0.1565, -0.4552, -0.1678,  0.2528, -0.0108,\n",
            "          -0.2839,  0.4584],\n",
            "         [-0.4381, -0.2211,  0.0315, -0.3052,  0.0483, -0.1721,  0.0634,\n",
            "           0.3309,  0.3796,  0.1012, -0.3481, -0.3058,  0.0316, -0.2430,\n",
            "          -0.3589,  0.3983]]], grad_fn=<TransposeBackward0>)\n",
            "After LayerNorm1 shape: torch.Size([1, 2, 16])\n",
            "After LayerNorm1 values:\n",
            " tensor([[[-0.4547, -0.3786, -2.4190, -0.9940,  0.0073, -0.8269,  0.1890,\n",
            "           1.2983,  1.3627,  0.3771,  1.0415, -0.2689,  0.8782,  1.0599,\n",
            "          -1.1340,  0.2619],\n",
            "         [-1.2599,  1.4795,  0.3727,  0.6625,  0.6636, -0.4990, -0.8812,\n",
            "          -0.1567, -1.1973,  0.3221, -1.6574,  1.9536, -0.1237, -0.6549,\n",
            "          -0.2650,  1.2410]]], grad_fn=<NativeLayerNormBackward0>)\n",
            "Feed Forward output shape: torch.Size([1, 2, 16])\n",
            "Feed Forward output values:\n",
            " tensor([[[ 0.1767, -0.0704, -0.2635,  0.0272,  0.0991,  0.0309,  0.4264,\n",
            "          -0.0759,  0.2952, -0.0718,  0.2363, -0.1369,  0.2899, -0.1068,\n",
            "           0.0181,  0.1246],\n",
            "         [ 0.4165,  0.3215, -0.1772,  0.1635,  0.1357, -0.2807,  0.1730,\n",
            "           0.0565,  0.0673, -0.2960,  0.0796, -0.5783,  0.2458, -0.0961,\n",
            "          -0.0746, -0.1002]]], grad_fn=<ViewBackward0>)\n",
            "After LayerNorm2 shape: torch.Size([1, 2, 16])\n",
            "After LayerNorm2 values:\n",
            " tensor([[[-0.3110, -0.4672, -2.5076, -0.9403,  0.0401, -0.7842,  0.5052,\n",
            "           1.0597,  1.4575,  0.2219,  1.1102, -0.4277,  1.0101,  0.8136,\n",
            "          -1.0765,  0.2961],\n",
            "         [-0.9026,  1.9156,  0.2046,  0.8765,  0.8481, -0.8347, -0.7585,\n",
            "          -0.1106, -1.2080,  0.0242, -1.6852,  1.4619,  0.1264, -0.8041,\n",
            "          -0.3656,  1.2120]]], grad_fn=<NativeLayerNormBackward0>)\n",
            "=================================\n",
            "\n",
            "\n",
            "===== FORWARD PASS GPTBlock =====\n",
            "Input tensor shape: torch.Size([1, 3, 16])\n",
            "Attention output shape: torch.Size([1, 3, 16])\n",
            "Attention output values:\n",
            " tensor([[[ 0.4976, -0.0425, -0.6015, -0.8495,  1.3402, -0.0253, -0.6126,\n",
            "           0.2388,  0.5035, -0.1005,  0.5271,  0.4137,  0.6495,  0.3852,\n",
            "           0.3827,  0.7076],\n",
            "         [-0.1732,  0.2964,  0.4973, -0.1324,  0.7904,  0.1026, -0.2555,\n",
            "           0.3387, -0.3192, -0.3305, -0.3001,  0.0357,  0.8668, -0.2059,\n",
            "          -0.1829, -0.1117],\n",
            "         [ 0.2393,  0.0277, -0.1970, -0.5139,  1.2433,  0.0248, -0.4456,\n",
            "           0.2180, -0.1885, -0.4944,  0.2644,  0.0676,  0.4795,  0.3262,\n",
            "           0.0954,  0.2970]]], grad_fn=<TransposeBackward0>)\n",
            "After LayerNorm1 shape: torch.Size([1, 3, 16])\n",
            "After LayerNorm1 values:\n",
            " tensor([[[ 0.2980, -0.1057, -2.5523, -0.7322, -0.2220, -0.7078, -0.1928,\n",
            "           0.9957,  1.1922,  0.4540,  1.5406, -0.0144,  0.2068,  1.2288,\n",
            "          -1.3077, -0.0813],\n",
            "         [-0.7321,  1.3929,  0.1498,  0.8795,  0.6939, -0.4162, -1.0340,\n",
            "          -0.4927, -1.8187, -0.1534, -1.4248,  2.0437, -0.2131, -0.2776,\n",
            "           0.4598,  0.9431],\n",
            "         [-0.5805,  0.7189, -1.2148,  0.5732,  0.7517, -1.6949,  0.2289,\n",
            "           1.4137, -1.0061,  1.1013,  0.0705, -1.8740, -0.3692,  1.3439,\n",
            "           0.1590,  0.3786]]], grad_fn=<NativeLayerNormBackward0>)\n",
            "Feed Forward output shape: torch.Size([1, 3, 16])\n",
            "Feed Forward output values:\n",
            " tensor([[[-0.3009,  0.0641, -0.5448, -0.2372,  0.1203, -0.1077,  0.3984,\n",
            "           0.2516,  0.2372,  0.0981,  0.2294, -0.2621,  0.5163,  0.0416,\n",
            "           0.0403, -0.2411],\n",
            "         [-0.1485,  0.2635,  0.1340,  0.0399, -0.1343,  0.0301,  0.0224,\n",
            "          -0.0624,  0.1660,  0.3150,  0.0520,  0.1765, -0.0031, -0.1932,\n",
            "          -0.4195, -0.1596],\n",
            "         [ 0.2986, -0.0251, -0.4124,  0.2672,  0.1472,  0.0781,  0.3257,\n",
            "           0.2660, -0.0584,  0.3823,  0.0237, -0.1341,  0.7628, -0.5207,\n",
            "          -0.0790, -0.1267]]], grad_fn=<ViewBackward0>)\n",
            "After LayerNorm2 shape: torch.Size([1, 3, 16])\n",
            "After LayerNorm2 values:\n",
            " tensor([[[-0.0186, -0.0514, -2.6451, -0.8389, -0.1024, -0.7083,  0.1584,\n",
            "           1.0427,  1.1972,  0.4526,  1.4864, -0.2508,  0.5977,  1.0623,\n",
            "          -1.0919, -0.2898],\n",
            "         [-0.8670,  1.6168,  0.2729,  0.8953,  0.5430, -0.3828, -0.9952,\n",
            "          -0.5483, -1.6229,  0.1534, -1.3488,  2.1688, -0.2165, -0.4657,\n",
            "           0.0347,  0.7622],\n",
            "         [-0.3303,  0.5733, -1.5762,  0.7091,  0.7633, -1.5665,  0.4444,\n",
            "           1.4864, -1.0550,  1.3048,  0.0180, -1.9289,  0.2954,  0.6931,\n",
            "           0.0049,  0.1641]]], grad_fn=<NativeLayerNormBackward0>)\n",
            "=================================\n",
            "\n",
            "\n",
            "===== FORWARD PASS GPTBlock =====\n",
            "Input tensor shape: torch.Size([1, 3, 16])\n",
            "Attention output shape: torch.Size([1, 3, 16])\n",
            "Attention output values:\n",
            " tensor([[[-0.6057, -0.4886, -0.1524, -0.3819, -0.0107, -0.3277, -0.0704,\n",
            "           0.2727,  0.1893, -0.1565, -0.4552, -0.1678,  0.2528, -0.0108,\n",
            "          -0.2839,  0.4584],\n",
            "         [-0.4381, -0.2211,  0.0315, -0.3052,  0.0483, -0.1721,  0.0634,\n",
            "           0.3309,  0.3796,  0.1012, -0.3481, -0.3058,  0.0316, -0.2430,\n",
            "          -0.3589,  0.3983],\n",
            "         [-0.0978, -0.2123, -0.3676, -0.2350,  0.0828, -0.3496,  0.0077,\n",
            "           0.3490,  0.1166, -0.1131,  0.0869,  0.2247,  0.4514, -0.4086,\n",
            "          -0.4722,  0.4590]]], grad_fn=<TransposeBackward0>)\n",
            "After LayerNorm1 shape: torch.Size([1, 3, 16])\n",
            "After LayerNorm1 values:\n",
            " tensor([[[-0.4547, -0.3786, -2.4190, -0.9940,  0.0073, -0.8269,  0.1890,\n",
            "           1.2983,  1.3627,  0.3771,  1.0415, -0.2689,  0.8782,  1.0599,\n",
            "          -1.1340,  0.2619],\n",
            "         [-1.2599,  1.4795,  0.3727,  0.6625,  0.6636, -0.4990, -0.8812,\n",
            "          -0.1567, -1.1973,  0.3221, -1.6574,  1.9536, -0.1237, -0.6549,\n",
            "          -0.2650,  1.2410],\n",
            "         [-0.3681,  0.3613, -1.7692,  0.4659,  0.8097, -1.7436,  0.4455,\n",
            "           1.7243, -0.8399,  1.1292,  0.1246, -1.5478,  0.7179,  0.2907,\n",
            "          -0.4043,  0.6036]]], grad_fn=<NativeLayerNormBackward0>)\n",
            "Feed Forward output shape: torch.Size([1, 3, 16])\n",
            "Feed Forward output values:\n",
            " tensor([[[ 0.1767, -0.0704, -0.2635,  0.0272,  0.0991,  0.0309,  0.4264,\n",
            "          -0.0759,  0.2952, -0.0718,  0.2363, -0.1369,  0.2899, -0.1068,\n",
            "           0.0181,  0.1246],\n",
            "         [ 0.4165,  0.3215, -0.1772,  0.1635,  0.1357, -0.2807,  0.1730,\n",
            "           0.0565,  0.0673, -0.2960,  0.0796, -0.5783,  0.2458, -0.0961,\n",
            "          -0.0746, -0.1002],\n",
            "         [-0.1974,  0.0752, -0.2818, -0.0429,  0.1684,  0.1246,  0.2311,\n",
            "           0.0326,  0.0778, -0.2077,  0.5253, -0.0718, -0.0056, -0.0923,\n",
            "           0.0955,  0.1366]]], grad_fn=<ViewBackward0>)\n",
            "After LayerNorm2 shape: torch.Size([1, 3, 16])\n",
            "After LayerNorm2 values:\n",
            " tensor([[[-0.3110, -0.4672, -2.5076, -0.9403,  0.0401, -0.7842,  0.5052,\n",
            "           1.0597,  1.4575,  0.2219,  1.1102, -0.4277,  1.0101,  0.8136,\n",
            "          -1.0765,  0.2961],\n",
            "         [-0.9026,  1.9156,  0.2046,  0.8765,  0.8481, -0.8347, -0.7585,\n",
            "          -0.1106, -1.2080,  0.0242, -1.6852,  1.4619,  0.1264, -0.8041,\n",
            "          -0.3656,  1.2120],\n",
            "         [-0.5720,  0.3817, -1.9858,  0.3688,  0.8972, -1.5746,  0.6103,\n",
            "           1.6383, -0.7591,  0.8433,  0.5848, -1.5752,  0.6441,  0.1551,\n",
            "          -0.3277,  0.6708]]], grad_fn=<NativeLayerNormBackward0>)\n",
            "=================================\n",
            "\n",
            "\n",
            "===== FORWARD PASS GPTBlock =====\n",
            "Input tensor shape: torch.Size([1, 4, 16])\n",
            "Attention output shape: torch.Size([1, 4, 16])\n",
            "Attention output values:\n",
            " tensor([[[ 4.9765e-01, -4.2507e-02, -6.0152e-01, -8.4951e-01,  1.3402e+00,\n",
            "          -2.5312e-02, -6.1263e-01,  2.3880e-01,  5.0353e-01, -1.0051e-01,\n",
            "           5.2706e-01,  4.1369e-01,  6.4949e-01,  3.8520e-01,  3.8268e-01,\n",
            "           7.0759e-01],\n",
            "         [-1.7321e-01,  2.9641e-01,  4.9734e-01, -1.3243e-01,  7.9041e-01,\n",
            "           1.0259e-01, -2.5552e-01,  3.3873e-01, -3.1919e-01, -3.3048e-01,\n",
            "          -3.0012e-01,  3.5675e-02,  8.6683e-01, -2.0589e-01, -1.8287e-01,\n",
            "          -1.1168e-01],\n",
            "         [ 2.3926e-01,  2.7681e-02, -1.9696e-01, -5.1388e-01,  1.2433e+00,\n",
            "           2.4805e-02, -4.4555e-01,  2.1805e-01, -1.8852e-01, -4.9443e-01,\n",
            "           2.6435e-01,  6.7607e-02,  4.7945e-01,  3.2621e-01,  9.5403e-02,\n",
            "           2.9701e-01],\n",
            "         [-1.4092e-01,  2.2581e-01, -1.0108e-03, -4.6498e-01,  1.1302e+00,\n",
            "           5.9146e-01, -4.0239e-01,  4.1894e-01, -5.7428e-01, -3.9141e-01,\n",
            "           7.1722e-02, -2.7981e-01,  6.9011e-02, -2.7683e-02, -4.0150e-01,\n",
            "          -2.3107e-01]]], grad_fn=<TransposeBackward0>)\n",
            "After LayerNorm1 shape: torch.Size([1, 4, 16])\n",
            "After LayerNorm1 values:\n",
            " tensor([[[ 0.2980, -0.1057, -2.5523, -0.7322, -0.2220, -0.7078, -0.1928,\n",
            "           0.9957,  1.1922,  0.4540,  1.5406, -0.0144,  0.2068,  1.2288,\n",
            "          -1.3077, -0.0813],\n",
            "         [-0.7321,  1.3929,  0.1498,  0.8795,  0.6939, -0.4162, -1.0340,\n",
            "          -0.4927, -1.8187, -0.1534, -1.4248,  2.0437, -0.2131, -0.2776,\n",
            "           0.4598,  0.9431],\n",
            "         [-0.5805,  0.7189, -1.2148,  0.5732,  0.7517, -1.6949,  0.2289,\n",
            "           1.4137, -1.0061,  1.1013,  0.0705, -1.8740, -0.3692,  1.3439,\n",
            "           0.1590,  0.3786],\n",
            "         [ 1.2858, -0.0610,  0.4523, -0.6685,  0.1233, -0.8607, -1.0307,\n",
            "           0.9799, -1.1092, -1.6254,  2.2365,  0.6609,  0.4772, -0.4270,\n",
            "           0.5241, -0.9577]]], grad_fn=<NativeLayerNormBackward0>)\n",
            "Feed Forward output shape: torch.Size([1, 4, 16])\n",
            "Feed Forward output values:\n",
            " tensor([[[-0.3009,  0.0641, -0.5448, -0.2372,  0.1203, -0.1077,  0.3984,\n",
            "           0.2516,  0.2372,  0.0981,  0.2294, -0.2621,  0.5163,  0.0416,\n",
            "           0.0403, -0.2411],\n",
            "         [-0.1485,  0.2635,  0.1340,  0.0399, -0.1343,  0.0301,  0.0224,\n",
            "          -0.0624,  0.1660,  0.3150,  0.0520,  0.1765, -0.0031, -0.1932,\n",
            "          -0.4195, -0.1596],\n",
            "         [ 0.2986, -0.0251, -0.4124,  0.2672,  0.1472,  0.0781,  0.3257,\n",
            "           0.2660, -0.0584,  0.3823,  0.0237, -0.1341,  0.7628, -0.5207,\n",
            "          -0.0790, -0.1267],\n",
            "         [-0.0491,  0.1142, -0.2121, -0.0389,  0.0625,  0.0563,  0.1029,\n",
            "           0.1364,  0.2868,  0.3091, -0.2084, -0.2064,  0.3699, -0.2615,\n",
            "          -0.1573, -0.0820]]], grad_fn=<ViewBackward0>)\n",
            "After LayerNorm2 shape: torch.Size([1, 4, 16])\n",
            "After LayerNorm2 values:\n",
            " tensor([[[-0.0186, -0.0514, -2.6451, -0.8389, -0.1024, -0.7083,  0.1584,\n",
            "           1.0427,  1.1972,  0.4526,  1.4864, -0.2508,  0.5977,  1.0623,\n",
            "          -1.0919, -0.2898],\n",
            "         [-0.8670,  1.6168,  0.2729,  0.8953,  0.5430, -0.3828, -0.9952,\n",
            "          -0.5483, -1.6229,  0.1534, -1.3488,  2.1688, -0.2165, -0.4657,\n",
            "           0.0347,  0.7622],\n",
            "         [-0.3303,  0.5733, -1.5762,  0.7091,  0.7633, -1.5665,  0.4444,\n",
            "           1.4864, -1.0550,  1.3048,  0.0180, -1.9289,  0.2954,  0.6931,\n",
            "           0.0049,  0.1641],\n",
            "         [ 1.3067,  0.0421,  0.2418, -0.7708,  0.1837, -0.8744, -1.0063,\n",
            "           1.1781, -0.8936, -1.4214,  2.1524,  0.4708,  0.8904, -0.7506,\n",
            "           0.3771, -1.1259]]], grad_fn=<NativeLayerNormBackward0>)\n",
            "=================================\n",
            "\n",
            "\n",
            "===== FORWARD PASS GPTBlock =====\n",
            "Input tensor shape: torch.Size([1, 4, 16])\n",
            "Attention output shape: torch.Size([1, 4, 16])\n",
            "Attention output values:\n",
            " tensor([[[-0.6057, -0.4886, -0.1524, -0.3819, -0.0107, -0.3277, -0.0704,\n",
            "           0.2727,  0.1893, -0.1565, -0.4552, -0.1678,  0.2528, -0.0108,\n",
            "          -0.2839,  0.4584],\n",
            "         [-0.4381, -0.2211,  0.0315, -0.3052,  0.0483, -0.1721,  0.0634,\n",
            "           0.3309,  0.3796,  0.1012, -0.3481, -0.3058,  0.0316, -0.2430,\n",
            "          -0.3589,  0.3983],\n",
            "         [-0.0978, -0.2123, -0.3676, -0.2350,  0.0828, -0.3496,  0.0077,\n",
            "           0.3490,  0.1166, -0.1131,  0.0869,  0.2247,  0.4514, -0.4086,\n",
            "          -0.4722,  0.4590],\n",
            "         [-0.4300,  0.0159, -0.0230,  0.0996,  0.2110, -0.2512,  0.1197,\n",
            "           0.0713,  0.5010,  0.3593, -0.1174, -0.2281, -0.0601, -0.2539,\n",
            "          -0.2525,  0.4082]]], grad_fn=<TransposeBackward0>)\n",
            "After LayerNorm1 shape: torch.Size([1, 4, 16])\n",
            "After LayerNorm1 values:\n",
            " tensor([[[-0.4547, -0.3786, -2.4190, -0.9940,  0.0073, -0.8269,  0.1890,\n",
            "           1.2983,  1.3627,  0.3771,  1.0415, -0.2689,  0.8782,  1.0599,\n",
            "          -1.1340,  0.2619],\n",
            "         [-1.2599,  1.4795,  0.3727,  0.6625,  0.6636, -0.4990, -0.8812,\n",
            "          -0.1567, -1.1973,  0.3221, -1.6574,  1.9536, -0.1237, -0.6549,\n",
            "          -0.2650,  1.2410],\n",
            "         [-0.3681,  0.3613, -1.7692,  0.4659,  0.8097, -1.7436,  0.4455,\n",
            "           1.7243, -0.8399,  1.1292,  0.1246, -1.5478,  0.7179,  0.2907,\n",
            "          -0.4043,  0.6036],\n",
            "         [ 0.9702,  0.0531,  0.2332, -0.7638,  0.4303, -1.2728, -1.0051,\n",
            "           1.3877, -0.4517, -1.2017,  2.2678,  0.2601,  0.9182, -1.1372,\n",
            "           0.1277, -0.8158]]], grad_fn=<NativeLayerNormBackward0>)\n",
            "Feed Forward output shape: torch.Size([1, 4, 16])\n",
            "Feed Forward output values:\n",
            " tensor([[[ 0.1767, -0.0704, -0.2635,  0.0272,  0.0991,  0.0309,  0.4264,\n",
            "          -0.0759,  0.2952, -0.0718,  0.2363, -0.1369,  0.2899, -0.1068,\n",
            "           0.0181,  0.1246],\n",
            "         [ 0.4165,  0.3215, -0.1772,  0.1635,  0.1357, -0.2807,  0.1730,\n",
            "           0.0565,  0.0673, -0.2960,  0.0796, -0.5783,  0.2458, -0.0961,\n",
            "          -0.0746, -0.1002],\n",
            "         [-0.1974,  0.0752, -0.2818, -0.0429,  0.1684,  0.1246,  0.2311,\n",
            "           0.0326,  0.0778, -0.2077,  0.5253, -0.0718, -0.0056, -0.0923,\n",
            "           0.0955,  0.1366],\n",
            "         [ 0.1023,  0.3405,  0.0843,  0.2545,  0.1612,  0.4516, -0.1464,\n",
            "          -0.4559, -0.2261, -0.1973,  0.3425, -0.2357,  0.0162, -0.5451,\n",
            "          -0.0254, -0.0079]]], grad_fn=<ViewBackward0>)\n",
            "After LayerNorm2 shape: torch.Size([1, 4, 16])\n",
            "After LayerNorm2 values:\n",
            " tensor([[[-0.3110, -0.4672, -2.5076, -0.9403,  0.0401, -0.7842,  0.5052,\n",
            "           1.0597,  1.4575,  0.2219,  1.1102, -0.4277,  1.0101,  0.8136,\n",
            "          -1.0765,  0.2961],\n",
            "         [-0.9026,  1.9156,  0.2046,  0.8765,  0.8481, -0.8347, -0.7585,\n",
            "          -0.1106, -1.2080,  0.0242, -1.6852,  1.4619,  0.1264, -0.8041,\n",
            "          -0.3656,  1.2120],\n",
            "         [-0.5720,  0.3817, -1.9858,  0.3688,  0.8972, -1.5746,  0.6103,\n",
            "           1.6383, -0.7591,  0.8433,  0.5848, -1.5752,  0.6441,  0.1551,\n",
            "          -0.3277,  0.6708],\n",
            "         [ 1.0023,  0.3710,  0.3003, -0.4685,  0.5550, -0.7586, -1.0656,\n",
            "           0.8714, -0.6252, -1.2958,  2.4321,  0.0277,  0.8739, -1.5592,\n",
            "           0.1002, -0.7609]]], grad_fn=<NativeLayerNormBackward0>)\n",
            "=================================\n",
            "\n",
            "\n",
            "===== FORWARD PASS GPTBlock =====\n",
            "Input tensor shape: torch.Size([1, 5, 16])\n",
            "Attention output shape: torch.Size([1, 5, 16])\n",
            "Attention output values:\n",
            " tensor([[[ 4.9765e-01, -4.2507e-02, -6.0152e-01, -8.4951e-01,  1.3402e+00,\n",
            "          -2.5312e-02, -6.1263e-01,  2.3880e-01,  5.0353e-01, -1.0051e-01,\n",
            "           5.2706e-01,  4.1369e-01,  6.4949e-01,  3.8520e-01,  3.8268e-01,\n",
            "           7.0759e-01],\n",
            "         [-1.7321e-01,  2.9641e-01,  4.9734e-01, -1.3243e-01,  7.9041e-01,\n",
            "           1.0259e-01, -2.5552e-01,  3.3873e-01, -3.1919e-01, -3.3048e-01,\n",
            "          -3.0012e-01,  3.5675e-02,  8.6683e-01, -2.0589e-01, -1.8287e-01,\n",
            "          -1.1168e-01],\n",
            "         [ 2.3926e-01,  2.7681e-02, -1.9696e-01, -5.1388e-01,  1.2433e+00,\n",
            "           2.4805e-02, -4.4555e-01,  2.1805e-01, -1.8852e-01, -4.9443e-01,\n",
            "           2.6435e-01,  6.7607e-02,  4.7945e-01,  3.2621e-01,  9.5403e-02,\n",
            "           2.9701e-01],\n",
            "         [-1.4092e-01,  2.2581e-01, -1.0108e-03, -4.6498e-01,  1.1302e+00,\n",
            "           5.9146e-01, -4.0239e-01,  4.1894e-01, -5.7428e-01, -3.9141e-01,\n",
            "           7.1722e-02, -2.7981e-01,  6.9011e-02, -2.7683e-02, -4.0150e-01,\n",
            "          -2.3107e-01],\n",
            "         [ 2.0453e-01,  2.3465e-01,  5.4211e-01, -2.9746e-01,  8.9258e-01,\n",
            "           2.5013e-01,  1.0442e-01,  2.2586e-01, -3.3586e-01, -3.9811e-01,\n",
            "          -1.1165e-01, -2.3684e-01,  3.3648e-01, -9.2803e-02, -1.7502e-01,\n",
            "          -2.3546e-01]]], grad_fn=<TransposeBackward0>)\n",
            "After LayerNorm1 shape: torch.Size([1, 5, 16])\n",
            "After LayerNorm1 values:\n",
            " tensor([[[ 0.2980, -0.1057, -2.5523, -0.7322, -0.2220, -0.7078, -0.1928,\n",
            "           0.9957,  1.1922,  0.4540,  1.5406, -0.0144,  0.2068,  1.2288,\n",
            "          -1.3077, -0.0813],\n",
            "         [-0.7321,  1.3929,  0.1498,  0.8795,  0.6939, -0.4162, -1.0340,\n",
            "          -0.4927, -1.8187, -0.1534, -1.4248,  2.0437, -0.2131, -0.2776,\n",
            "           0.4598,  0.9431],\n",
            "         [-0.5805,  0.7189, -1.2148,  0.5732,  0.7517, -1.6949,  0.2289,\n",
            "           1.4137, -1.0061,  1.1013,  0.0705, -1.8740, -0.3692,  1.3439,\n",
            "           0.1590,  0.3786],\n",
            "         [ 1.2858, -0.0610,  0.4523, -0.6685,  0.1233, -0.8607, -1.0307,\n",
            "           0.9799, -1.1092, -1.6254,  2.2365,  0.6609,  0.4772, -0.4270,\n",
            "           0.5241, -0.9577],\n",
            "         [-0.0308,  1.9136,  1.9034, -0.4300,  0.7355, -0.2146, -1.1951,\n",
            "          -0.9815, -1.0816, -0.2780,  1.5316, -0.1500, -0.4528, -0.9808,\n",
            "          -0.7471,  0.4581]]], grad_fn=<NativeLayerNormBackward0>)\n",
            "Feed Forward output shape: torch.Size([1, 5, 16])\n",
            "Feed Forward output values:\n",
            " tensor([[[-0.3009,  0.0641, -0.5448, -0.2372,  0.1203, -0.1077,  0.3984,\n",
            "           0.2516,  0.2372,  0.0981,  0.2294, -0.2621,  0.5163,  0.0416,\n",
            "           0.0403, -0.2411],\n",
            "         [-0.1485,  0.2635,  0.1340,  0.0399, -0.1343,  0.0301,  0.0224,\n",
            "          -0.0624,  0.1660,  0.3150,  0.0520,  0.1765, -0.0031, -0.1932,\n",
            "          -0.4195, -0.1596],\n",
            "         [ 0.2986, -0.0251, -0.4124,  0.2672,  0.1472,  0.0781,  0.3257,\n",
            "           0.2660, -0.0584,  0.3823,  0.0237, -0.1341,  0.7628, -0.5207,\n",
            "          -0.0790, -0.1267],\n",
            "         [-0.0491,  0.1142, -0.2121, -0.0389,  0.0625,  0.0563,  0.1029,\n",
            "           0.1364,  0.2868,  0.3091, -0.2084, -0.2064,  0.3699, -0.2615,\n",
            "          -0.1573, -0.0820],\n",
            "         [-0.3001,  0.3638, -0.0357, -0.0185, -0.1367, -0.0892, -0.0851,\n",
            "           0.2295,  0.0957,  0.4537, -0.2573, -0.1418,  0.0379, -0.0658,\n",
            "          -0.2629, -0.0241]]], grad_fn=<ViewBackward0>)\n",
            "After LayerNorm2 shape: torch.Size([1, 5, 16])\n",
            "After LayerNorm2 values:\n",
            " tensor([[[-0.0186, -0.0514, -2.6451, -0.8389, -0.1024, -0.7083,  0.1584,\n",
            "           1.0427,  1.1972,  0.4526,  1.4864, -0.2508,  0.5977,  1.0623,\n",
            "          -1.0919, -0.2898],\n",
            "         [-0.8670,  1.6168,  0.2729,  0.8953,  0.5430, -0.3828, -0.9952,\n",
            "          -0.5483, -1.6229,  0.1534, -1.3488,  2.1688, -0.2165, -0.4657,\n",
            "           0.0347,  0.7622],\n",
            "         [-0.3303,  0.5733, -1.5762,  0.7091,  0.7633, -1.5665,  0.4444,\n",
            "           1.4864, -1.0550,  1.3048,  0.0180, -1.9289,  0.2954,  0.6931,\n",
            "           0.0049,  0.1641],\n",
            "         [ 1.3067,  0.0421,  0.2418, -0.7708,  0.1837, -0.8744, -1.0063,\n",
            "           1.1781, -0.8936, -1.4214,  2.1524,  0.4708,  0.8904, -0.7506,\n",
            "           0.3771, -1.1259],\n",
            "         [-0.3083,  2.2352,  1.8358, -0.4230,  0.5984, -0.2818, -1.2340,\n",
            "          -0.7189, -0.9470,  0.1858,  1.2571, -0.2701, -0.3902, -1.0062,\n",
            "          -0.9705,  0.4376]]], grad_fn=<NativeLayerNormBackward0>)\n",
            "=================================\n",
            "\n",
            "\n",
            "===== FORWARD PASS GPTBlock =====\n",
            "Input tensor shape: torch.Size([1, 5, 16])\n",
            "Attention output shape: torch.Size([1, 5, 16])\n",
            "Attention output values:\n",
            " tensor([[[-0.6057, -0.4886, -0.1524, -0.3819, -0.0107, -0.3277, -0.0704,\n",
            "           0.2727,  0.1893, -0.1565, -0.4552, -0.1678,  0.2528, -0.0108,\n",
            "          -0.2839,  0.4584],\n",
            "         [-0.4381, -0.2211,  0.0315, -0.3052,  0.0483, -0.1721,  0.0634,\n",
            "           0.3309,  0.3796,  0.1012, -0.3481, -0.3058,  0.0316, -0.2430,\n",
            "          -0.3589,  0.3983],\n",
            "         [-0.0978, -0.2123, -0.3676, -0.2350,  0.0828, -0.3496,  0.0077,\n",
            "           0.3490,  0.1166, -0.1131,  0.0869,  0.2247,  0.4514, -0.4086,\n",
            "          -0.4722,  0.4590],\n",
            "         [-0.4300,  0.0159, -0.0230,  0.0996,  0.2110, -0.2512,  0.1197,\n",
            "           0.0713,  0.5010,  0.3593, -0.1174, -0.2281, -0.0601, -0.2539,\n",
            "          -0.2525,  0.4082],\n",
            "         [-0.3589,  0.1447, -0.0069,  0.1569,  0.1891, -0.1597,  0.2813,\n",
            "           0.0420,  0.3701,  0.3420, -0.2260, -0.0611,  0.0572, -0.2734,\n",
            "          -0.3273,  0.2786]]], grad_fn=<TransposeBackward0>)\n",
            "After LayerNorm1 shape: torch.Size([1, 5, 16])\n",
            "After LayerNorm1 values:\n",
            " tensor([[[-0.4547, -0.3786, -2.4190, -0.9940,  0.0073, -0.8269,  0.1890,\n",
            "           1.2983,  1.3627,  0.3771,  1.0415, -0.2689,  0.8782,  1.0599,\n",
            "          -1.1340,  0.2619],\n",
            "         [-1.2599,  1.4795,  0.3727,  0.6625,  0.6636, -0.4990, -0.8812,\n",
            "          -0.1567, -1.1973,  0.3221, -1.6574,  1.9536, -0.1237, -0.6549,\n",
            "          -0.2650,  1.2410],\n",
            "         [-0.3681,  0.3613, -1.7692,  0.4659,  0.8097, -1.7436,  0.4455,\n",
            "           1.7243, -0.8399,  1.1292,  0.1246, -1.5478,  0.7179,  0.2907,\n",
            "          -0.4043,  0.6036],\n",
            "         [ 0.9702,  0.0531,  0.2332, -0.7638,  0.4303, -1.2728, -1.0051,\n",
            "           1.3877, -0.4517, -1.2017,  2.2678,  0.2601,  0.9182, -1.1372,\n",
            "           0.1277, -0.8158],\n",
            "         [-0.6662,  2.2539,  1.7257, -0.2819,  0.7278, -0.4500, -0.9399,\n",
            "          -0.6755, -0.5797,  0.4790,  0.9612, -0.3442, -0.3460, -1.2530,\n",
            "          -1.2706,  0.6594]]], grad_fn=<NativeLayerNormBackward0>)\n",
            "Feed Forward output shape: torch.Size([1, 5, 16])\n",
            "Feed Forward output values:\n",
            " tensor([[[ 0.1767, -0.0704, -0.2635,  0.0272,  0.0991,  0.0309,  0.4264,\n",
            "          -0.0759,  0.2952, -0.0718,  0.2363, -0.1369,  0.2899, -0.1068,\n",
            "           0.0181,  0.1246],\n",
            "         [ 0.4165,  0.3215, -0.1772,  0.1635,  0.1357, -0.2807,  0.1730,\n",
            "           0.0565,  0.0673, -0.2960,  0.0796, -0.5783,  0.2458, -0.0961,\n",
            "          -0.0746, -0.1002],\n",
            "         [-0.1974,  0.0752, -0.2818, -0.0429,  0.1684,  0.1246,  0.2311,\n",
            "           0.0326,  0.0778, -0.2077,  0.5253, -0.0718, -0.0056, -0.0923,\n",
            "           0.0955,  0.1366],\n",
            "         [ 0.1023,  0.3405,  0.0843,  0.2545,  0.1612,  0.4516, -0.1464,\n",
            "          -0.4559, -0.2261, -0.1973,  0.3425, -0.2357,  0.0162, -0.5451,\n",
            "          -0.0254, -0.0079],\n",
            "         [ 0.3378,  0.3611, -0.2483,  0.1757, -0.1217, -0.0494, -0.0320,\n",
            "          -0.1644, -0.1356, -0.2327,  0.3447, -0.2719,  0.0518, -0.1524,\n",
            "          -0.0015, -0.3241]]], grad_fn=<ViewBackward0>)\n",
            "After LayerNorm2 shape: torch.Size([1, 5, 16])\n",
            "After LayerNorm2 values:\n",
            " tensor([[[-0.3110, -0.4672, -2.5076, -0.9403,  0.0401, -0.7842,  0.5052,\n",
            "           1.0597,  1.4575,  0.2219,  1.1102, -0.4277,  1.0101,  0.8136,\n",
            "          -1.0765,  0.2961],\n",
            "         [-0.9026,  1.9156,  0.2046,  0.8765,  0.8481, -0.8347, -0.7585,\n",
            "          -0.1106, -1.2080,  0.0242, -1.6852,  1.4619,  0.1264, -0.8041,\n",
            "          -0.3656,  1.2120],\n",
            "         [-0.5720,  0.3817, -1.9858,  0.3688,  0.8972, -1.5746,  0.6103,\n",
            "           1.6383, -0.7591,  0.8433,  0.5848, -1.5752,  0.6441,  0.1551,\n",
            "          -0.3277,  0.6708],\n",
            "         [ 1.0023,  0.3710,  0.3003, -0.4685,  0.5550, -0.7586, -1.0656,\n",
            "           0.8714, -0.6252, -1.2958,  2.4321,  0.0277,  0.8739, -1.5592,\n",
            "           0.1002, -0.7609],\n",
            "         [-0.2836,  2.5036,  1.4264, -0.0732,  0.6013, -0.4455, -0.8929,\n",
            "          -0.7679, -0.6499,  0.2606,  1.2640, -0.5560, -0.2512, -1.3035,\n",
            "          -1.1772,  0.3450]]], grad_fn=<NativeLayerNormBackward0>)\n",
            "=================================\n",
            "\n",
            "\n",
            "===== FORWARD PASS GPTBlock =====\n",
            "Input tensor shape: torch.Size([1, 6, 16])\n",
            "Attention output shape: torch.Size([1, 6, 16])\n",
            "Attention output values:\n",
            " tensor([[[ 4.9765e-01, -4.2507e-02, -6.0152e-01, -8.4951e-01,  1.3402e+00,\n",
            "          -2.5312e-02, -6.1263e-01,  2.3880e-01,  5.0353e-01, -1.0051e-01,\n",
            "           5.2706e-01,  4.1369e-01,  6.4949e-01,  3.8520e-01,  3.8268e-01,\n",
            "           7.0759e-01],\n",
            "         [-1.7321e-01,  2.9641e-01,  4.9734e-01, -1.3243e-01,  7.9041e-01,\n",
            "           1.0259e-01, -2.5552e-01,  3.3873e-01, -3.1919e-01, -3.3048e-01,\n",
            "          -3.0012e-01,  3.5675e-02,  8.6683e-01, -2.0589e-01, -1.8287e-01,\n",
            "          -1.1168e-01],\n",
            "         [ 2.3926e-01,  2.7681e-02, -1.9696e-01, -5.1388e-01,  1.2433e+00,\n",
            "           2.4805e-02, -4.4555e-01,  2.1805e-01, -1.8852e-01, -4.9443e-01,\n",
            "           2.6435e-01,  6.7607e-02,  4.7945e-01,  3.2621e-01,  9.5403e-02,\n",
            "           2.9701e-01],\n",
            "         [-1.4092e-01,  2.2581e-01, -1.0108e-03, -4.6498e-01,  1.1302e+00,\n",
            "           5.9146e-01, -4.0239e-01,  4.1894e-01, -5.7428e-01, -3.9141e-01,\n",
            "           7.1722e-02, -2.7981e-01,  6.9011e-02, -2.7683e-02, -4.0150e-01,\n",
            "          -2.3107e-01],\n",
            "         [ 2.0453e-01,  2.3465e-01,  5.4211e-01, -2.9746e-01,  8.9258e-01,\n",
            "           2.5013e-01,  1.0442e-01,  2.2586e-01, -3.3586e-01, -3.9811e-01,\n",
            "          -1.1165e-01, -2.3684e-01,  3.3648e-01, -9.2803e-02, -1.7502e-01,\n",
            "          -2.3546e-01],\n",
            "         [ 4.4964e-01,  1.5979e-01,  5.4812e-01, -3.8799e-01,  9.6991e-01,\n",
            "           1.6267e-01,  2.4586e-01,  2.1444e-01, -2.8224e-01, -4.4648e-01,\n",
            "          -3.4288e-02, -2.5712e-01,  2.6357e-01,  5.9997e-02, -5.5843e-02,\n",
            "          -1.3066e-01]]], grad_fn=<TransposeBackward0>)\n",
            "After LayerNorm1 shape: torch.Size([1, 6, 16])\n",
            "After LayerNorm1 values:\n",
            " tensor([[[ 0.2980, -0.1057, -2.5523, -0.7322, -0.2220, -0.7078, -0.1928,\n",
            "           0.9957,  1.1922,  0.4540,  1.5406, -0.0144,  0.2068,  1.2288,\n",
            "          -1.3077, -0.0813],\n",
            "         [-0.7321,  1.3929,  0.1498,  0.8795,  0.6939, -0.4162, -1.0340,\n",
            "          -0.4927, -1.8187, -0.1534, -1.4248,  2.0437, -0.2131, -0.2776,\n",
            "           0.4598,  0.9431],\n",
            "         [-0.5805,  0.7189, -1.2148,  0.5732,  0.7517, -1.6949,  0.2289,\n",
            "           1.4137, -1.0061,  1.1013,  0.0705, -1.8740, -0.3692,  1.3439,\n",
            "           0.1590,  0.3786],\n",
            "         [ 1.2858, -0.0610,  0.4523, -0.6685,  0.1233, -0.8607, -1.0307,\n",
            "           0.9799, -1.1092, -1.6254,  2.2365,  0.6609,  0.4772, -0.4270,\n",
            "           0.5241, -0.9577],\n",
            "         [-0.0308,  1.9136,  1.9034, -0.4300,  0.7355, -0.2146, -1.1951,\n",
            "          -0.9815, -1.0816, -0.2780,  1.5316, -0.1500, -0.4528, -0.9808,\n",
            "          -0.7471,  0.4581],\n",
            "         [ 0.2138,  0.6955,  1.4208, -1.1285,  0.9133,  1.1375, -1.0179,\n",
            "           1.1270, -1.0838, -1.7456,  0.9269, -1.2118, -0.7875,  0.6147,\n",
            "           0.2742, -0.3486]]], grad_fn=<NativeLayerNormBackward0>)\n",
            "Feed Forward output shape: torch.Size([1, 6, 16])\n",
            "Feed Forward output values:\n",
            " tensor([[[-0.3009,  0.0641, -0.5448, -0.2372,  0.1203, -0.1077,  0.3984,\n",
            "           0.2516,  0.2372,  0.0981,  0.2294, -0.2621,  0.5163,  0.0416,\n",
            "           0.0403, -0.2411],\n",
            "         [-0.1485,  0.2635,  0.1340,  0.0399, -0.1343,  0.0301,  0.0224,\n",
            "          -0.0624,  0.1660,  0.3150,  0.0520,  0.1765, -0.0031, -0.1932,\n",
            "          -0.4195, -0.1596],\n",
            "         [ 0.2986, -0.0251, -0.4124,  0.2672,  0.1472,  0.0781,  0.3257,\n",
            "           0.2660, -0.0584,  0.3823,  0.0237, -0.1341,  0.7628, -0.5207,\n",
            "          -0.0790, -0.1267],\n",
            "         [-0.0491,  0.1142, -0.2121, -0.0389,  0.0625,  0.0563,  0.1029,\n",
            "           0.1364,  0.2868,  0.3091, -0.2084, -0.2064,  0.3699, -0.2615,\n",
            "          -0.1573, -0.0820],\n",
            "         [-0.3001,  0.3638, -0.0357, -0.0185, -0.1367, -0.0892, -0.0851,\n",
            "           0.2295,  0.0957,  0.4537, -0.2573, -0.1418,  0.0379, -0.0658,\n",
            "          -0.2629, -0.0241],\n",
            "         [-0.0471, -0.0156, -0.4172, -0.2317,  0.2786, -0.0299,  0.3927,\n",
            "           0.2816,  0.0299,  0.4180,  0.0060,  0.0464,  0.2323, -0.1959,\n",
            "           0.0173, -0.1987]]], grad_fn=<ViewBackward0>)\n",
            "After LayerNorm2 shape: torch.Size([1, 6, 16])\n",
            "After LayerNorm2 values:\n",
            " tensor([[[-0.0186, -0.0514, -2.6451, -0.8389, -0.1024, -0.7083,  0.1584,\n",
            "           1.0427,  1.1972,  0.4526,  1.4864, -0.2508,  0.5977,  1.0623,\n",
            "          -1.0919, -0.2898],\n",
            "         [-0.8670,  1.6168,  0.2729,  0.8953,  0.5430, -0.3828, -0.9952,\n",
            "          -0.5483, -1.6229,  0.1534, -1.3488,  2.1688, -0.2165, -0.4657,\n",
            "           0.0347,  0.7622],\n",
            "         [-0.3303,  0.5733, -1.5762,  0.7091,  0.7633, -1.5665,  0.4444,\n",
            "           1.4864, -1.0550,  1.3048,  0.0180, -1.9289,  0.2954,  0.6931,\n",
            "           0.0049,  0.1641],\n",
            "         [ 1.3067,  0.0421,  0.2418, -0.7708,  0.1837, -0.8744, -1.0063,\n",
            "           1.1781, -0.8936, -1.4214,  2.1524,  0.4708,  0.8904, -0.7506,\n",
            "           0.3771, -1.1259],\n",
            "         [-0.3083,  2.2352,  1.8358, -0.4230,  0.5984, -0.2818, -1.2340,\n",
            "          -0.7189, -0.9470,  0.1858,  1.2571, -0.2701, -0.3902, -1.0062,\n",
            "          -0.9705,  0.4376],\n",
            "         [ 0.1387,  0.6812,  1.0233, -1.4752,  1.2225,  1.1334, -0.6983,\n",
            "           1.4516, -1.1515, -1.4407,  0.9487, -1.2693, -0.6244,  0.4052,\n",
            "           0.2707, -0.6160]]], grad_fn=<NativeLayerNormBackward0>)\n",
            "=================================\n",
            "\n",
            "\n",
            "===== FORWARD PASS GPTBlock =====\n",
            "Input tensor shape: torch.Size([1, 6, 16])\n",
            "Attention output shape: torch.Size([1, 6, 16])\n",
            "Attention output values:\n",
            " tensor([[[-0.6057, -0.4886, -0.1524, -0.3819, -0.0107, -0.3277, -0.0704,\n",
            "           0.2727,  0.1893, -0.1565, -0.4552, -0.1678,  0.2528, -0.0108,\n",
            "          -0.2839,  0.4584],\n",
            "         [-0.4381, -0.2211,  0.0315, -0.3052,  0.0483, -0.1721,  0.0634,\n",
            "           0.3309,  0.3796,  0.1012, -0.3481, -0.3058,  0.0316, -0.2430,\n",
            "          -0.3589,  0.3983],\n",
            "         [-0.0978, -0.2123, -0.3676, -0.2350,  0.0828, -0.3496,  0.0077,\n",
            "           0.3490,  0.1166, -0.1131,  0.0869,  0.2247,  0.4514, -0.4086,\n",
            "          -0.4722,  0.4590],\n",
            "         [-0.4300,  0.0159, -0.0230,  0.0996,  0.2110, -0.2512,  0.1197,\n",
            "           0.0713,  0.5010,  0.3593, -0.1174, -0.2281, -0.0601, -0.2539,\n",
            "          -0.2525,  0.4082],\n",
            "         [-0.3589,  0.1447, -0.0069,  0.1569,  0.1891, -0.1597,  0.2813,\n",
            "           0.0420,  0.3701,  0.3420, -0.2260, -0.0611,  0.0572, -0.2734,\n",
            "          -0.3273,  0.2786],\n",
            "         [-0.3167,  0.2034,  0.0348,  0.1951,  0.1194, -0.1610,  0.2837,\n",
            "          -0.0145,  0.2278,  0.3345, -0.1929, -0.0904, -0.0764, -0.2032,\n",
            "          -0.1146,  0.1824]]], grad_fn=<TransposeBackward0>)\n",
            "After LayerNorm1 shape: torch.Size([1, 6, 16])\n",
            "After LayerNorm1 values:\n",
            " tensor([[[-0.4547, -0.3786, -2.4190, -0.9940,  0.0073, -0.8269,  0.1890,\n",
            "           1.2983,  1.3627,  0.3771,  1.0415, -0.2689,  0.8782,  1.0599,\n",
            "          -1.1340,  0.2619],\n",
            "         [-1.2599,  1.4795,  0.3727,  0.6625,  0.6636, -0.4990, -0.8812,\n",
            "          -0.1567, -1.1973,  0.3221, -1.6574,  1.9536, -0.1237, -0.6549,\n",
            "          -0.2650,  1.2410],\n",
            "         [-0.3681,  0.3613, -1.7692,  0.4659,  0.8097, -1.7436,  0.4455,\n",
            "           1.7243, -0.8399,  1.1292,  0.1246, -1.5478,  0.7179,  0.2907,\n",
            "          -0.4043,  0.6036],\n",
            "         [ 0.9702,  0.0531,  0.2332, -0.7638,  0.4303, -1.2728, -1.0051,\n",
            "           1.3877, -0.4517, -1.2017,  2.2678,  0.2601,  0.9182, -1.1372,\n",
            "           0.1277, -0.8158],\n",
            "         [-0.6662,  2.2539,  1.7257, -0.2819,  0.7278, -0.4500, -0.9399,\n",
            "          -0.6755, -0.5797,  0.4790,  0.9612, -0.3442, -0.3460, -1.2530,\n",
            "          -1.2706,  0.6594],\n",
            "         [-0.2195,  0.9253,  1.1122, -1.4067,  1.4179,  1.0198, -0.4743,\n",
            "           1.5205, -1.0228, -1.2194,  0.7865, -1.4924, -0.7826,  0.1899,\n",
            "           0.1405, -0.4949]]], grad_fn=<NativeLayerNormBackward0>)\n",
            "Feed Forward output shape: torch.Size([1, 6, 16])\n",
            "Feed Forward output values:\n",
            " tensor([[[ 0.1767, -0.0704, -0.2635,  0.0272,  0.0991,  0.0309,  0.4264,\n",
            "          -0.0759,  0.2952, -0.0718,  0.2363, -0.1369,  0.2899, -0.1068,\n",
            "           0.0181,  0.1246],\n",
            "         [ 0.4165,  0.3215, -0.1772,  0.1635,  0.1357, -0.2807,  0.1730,\n",
            "           0.0565,  0.0673, -0.2960,  0.0796, -0.5783,  0.2458, -0.0961,\n",
            "          -0.0746, -0.1002],\n",
            "         [-0.1974,  0.0752, -0.2818, -0.0429,  0.1684,  0.1246,  0.2311,\n",
            "           0.0326,  0.0778, -0.2077,  0.5253, -0.0718, -0.0056, -0.0923,\n",
            "           0.0955,  0.1366],\n",
            "         [ 0.1023,  0.3405,  0.0843,  0.2545,  0.1612,  0.4516, -0.1464,\n",
            "          -0.4559, -0.2261, -0.1973,  0.3425, -0.2357,  0.0162, -0.5451,\n",
            "          -0.0254, -0.0079],\n",
            "         [ 0.3378,  0.3611, -0.2483,  0.1757, -0.1217, -0.0494, -0.0320,\n",
            "          -0.1644, -0.1356, -0.2327,  0.3447, -0.2719,  0.0518, -0.1524,\n",
            "          -0.0015, -0.3241],\n",
            "         [ 0.0344,  0.2348, -0.0889,  0.1542,  0.2415,  0.2550, -0.2387,\n",
            "          -0.3196, -0.4264, -0.0978,  0.1707, -0.2350,  0.1140, -0.4291,\n",
            "          -0.0351, -0.0565]]], grad_fn=<ViewBackward0>)\n",
            "After LayerNorm2 shape: torch.Size([1, 6, 16])\n",
            "After LayerNorm2 values:\n",
            " tensor([[[-0.3110, -0.4672, -2.5076, -0.9403,  0.0401, -0.7842,  0.5052,\n",
            "           1.0597,  1.4575,  0.2219,  1.1102, -0.4277,  1.0101,  0.8136,\n",
            "          -1.0765,  0.2961],\n",
            "         [-0.9026,  1.9156,  0.2046,  0.8765,  0.8481, -0.8347, -0.7585,\n",
            "          -0.1106, -1.2080,  0.0242, -1.6852,  1.4619,  0.1264, -0.8041,\n",
            "          -0.3656,  1.2120],\n",
            "         [-0.5720,  0.3817, -1.9858,  0.3688,  0.8972, -1.5746,  0.6103,\n",
            "           1.6383, -0.7591,  0.8433,  0.5848, -1.5752,  0.6441,  0.1551,\n",
            "          -0.3277,  0.6708],\n",
            "         [ 1.0023,  0.3710,  0.3003, -0.4685,  0.5550, -0.7586, -1.0656,\n",
            "           0.8714, -0.6252, -1.2958,  2.4321,  0.0277,  0.8739, -1.5592,\n",
            "           0.1002, -0.7609],\n",
            "         [-0.2836,  2.5036,  1.4264, -0.0732,  0.6013, -0.4455, -0.8929,\n",
            "          -0.7679, -0.6499,  0.2606,  1.2640, -0.5560, -0.2512, -1.3035,\n",
            "          -1.1772,  0.3450],\n",
            "         [-0.1289,  1.1105,  0.9844, -1.1124,  1.5705,  1.2162, -0.6153,\n",
            "           1.1481, -1.2936, -1.1720,  0.9235, -1.5500, -0.5745, -0.1788,\n",
            "           0.1386, -0.4664]]], grad_fn=<NativeLayerNormBackward0>)\n",
            "=================================\n",
            "\n",
            "Generated Text: hello world test this is a is\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from qiskit import QuantumCircuit\n",
        "from qiskit.circuit.library import ZZFeatureMap, RealAmplitudes\n",
        "from qiskit.primitives import StatevectorEstimator  # Ganti dari Estimator (Deprecated)\n",
        "from qiskit_machine_learning.neural_networks import EstimatorQNN\n",
        "from qiskit_machine_learning.connectors import TorchConnector\n",
        "\n",
        "class QuantumNeuralNetwork(nn.Module):\n",
        "    def __init__(self, num_features, num_qubits, reps=1):\n",
        "        super(QuantumNeuralNetwork, self).__init__()\n",
        "\n",
        "        self.num_features = num_features\n",
        "        self.num_qubits = num_qubits  # Menggunakan jumlah qubit sesuai input\n",
        "\n",
        "        # Gunakan StatevectorEstimator (V2) sebagai pengganti Estimator (V1)\n",
        "        estimator = StatevectorEstimator()\n",
        "\n",
        "        # Feature map & ansatz\n",
        "        feature_map = ZZFeatureMap(self.num_qubits)\n",
        "        ansatz = RealAmplitudes(self.num_qubits, reps=reps)\n",
        "\n",
        "        # Quantum Circuit\n",
        "        qc = QuantumCircuit(self.num_qubits)\n",
        "        qc.compose(feature_map, inplace=True)\n",
        "        qc.compose(ansatz, inplace=True)\n",
        "\n",
        "        # Definisi QNN\n",
        "        qnn = EstimatorQNN(\n",
        "            circuit=qc,\n",
        "            input_params=feature_map.parameters,\n",
        "            weight_params=ansatz.parameters,\n",
        "            input_gradients=True,\n",
        "            estimator=estimator,\n",
        "        )\n",
        "\n",
        "        # Menghubungkan dengan PyTorch menggunakan TorchConnector\n",
        "        self.qnn_layer = TorchConnector(qnn)\n",
        "\n",
        "        # Fully connected layer setelah QNN\n",
        "        self.fc = nn.Linear(1, 1)  # Output QNN adalah skalar, jadi Linear(1, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        batch_size, seq_length, feature_dim = x.shape\n",
        "\n",
        "        # Pastikan feature_dim sesuai dengan num_features\n",
        "        if feature_dim != self.num_features:\n",
        "            raise ValueError(f\"Input feature_dim={feature_dim}, but expected {self.num_features}\")\n",
        "\n",
        "        # Ubah input agar sesuai untuk QNN\n",
        "        x = x.view(batch_size * seq_length, feature_dim)\n",
        "\n",
        "        x = self.qnn_layer(x)  # Proses di QNN (Output adalah skalar per input)\n",
        "\n",
        "        x = self.fc(x)  # Masukkan ke Fully Connected Layer\n",
        "        x = x.view(batch_size, seq_length, -1)  # Kembalikan ke ukuran semula\n",
        "\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "jhRJFoMIz8NB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Contoh tensor input\n",
        "x = torch.randn(1, 6, 16)  # (batch_size=1, seq_length=6, num_features=16)\n",
        "\n",
        "# Membuat model dengan num_features=16 dan num_qubits=2 (bisa diubah)\n",
        "model = QuantumNeuralNetwork(num_features=16, num_qubits=16)\n",
        "\n",
        "# Forward pass\n",
        "output = model(x)\n",
        "print(output.shape)  # Seharusnya (1, 6, 1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 410
        },
        "id": "dPPzfIBY34Co",
        "outputId": "7ba77d3e-2064-4036-8228-56d4667d1a7e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:qiskit_machine_learning.neural_networks.estimator_qnn:No gradient function provided, creating a gradient function. If your Estimator requires transpilation, please provide a pass manager.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "QiskitMachineLearningError",
          "evalue": "'Invalid input dimension! Received torch.Size([6, 16]) and expected input compatible to 2'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mQiskitMachineLearningError\u001b[0m                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-37-7654b0d8a3df>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# Forward pass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Seharusnya (1, 6, 1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-33-dc2ce12c024b>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     51\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mseq_length\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqnn_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Proses di QNN (Output adalah skalar per input)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Masukkan ke Fully Connected Layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/qiskit_machine_learning/connectors/torch_connector.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_data)\u001b[0m\n\u001b[1;32m    421\u001b[0m             \u001b[0minput_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    422\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 423\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_TorchNNFunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_weights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_neural_network\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sparse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/autograd/function.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m    573\u001b[0m             \u001b[0;31m# See NOTE: [functorch vjp and autograd interaction]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m             \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_functorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap_dead_wrappers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 575\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    576\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    577\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_setup_ctx_defined\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/qiskit_machine_learning/connectors/torch_connector.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(ctx, input_data, weights, neural_network, sparse)\u001b[0m\n\u001b[1;32m    153\u001b[0m         \"\"\"\n\u001b[1;32m    154\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minput_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mneural_network\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_inputs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 155\u001b[0;31m             raise QiskitMachineLearningError(\n\u001b[0m\u001b[1;32m    156\u001b[0m                 \u001b[0;34mf\"Invalid input dimension! Received {input_data.shape} and \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m                 \u001b[0;34m+\u001b[0m \u001b[0;34mf\"expected input compatible to {neural_network.num_inputs}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mQiskitMachineLearningError\u001b[0m: 'Invalid input dimension! Received torch.Size([6, 16]) and expected input compatible to 2'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_TQFy5IR35f3",
        "outputId": "09bfa3f5-4ec9-4e16-98d8-2d32a35c336f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[-0.5048],\n",
              "         [-0.5093],\n",
              "         [-0.5014],\n",
              "         [-0.5109],\n",
              "         [-0.5039],\n",
              "         [-0.5010]]], grad_fn=<ViewBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FRS-c79F5qyI"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}