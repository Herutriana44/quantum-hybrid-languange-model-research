# Penelitian Model Bahasa Kuantum-Hibrida

## Deskripsi
Repository ini berisi penelitian terkait integrasi Komputasi Kuantum dengan Model Bahasa Besar (Large Language Models / LLM). Fokus utama dari proyek ini adalah pengembangan *Quantum-Hybrid-LLMs*, yang menggabungkan kekuatan model seperti GPT-2, T5-small, dan Word2Vec dengan lapisan kuantum untuk mengeksplorasi potensi peningkatan dalam pemrosesan bahasa alami (NLP).

Penambahan lapisan kuantum diharapkan dapat memberikan keuntungan seperti peningkatan efisiensi komputasi, pemrosesan data yang lebih cepat, dan potensi peningkatan kemampuan model dalam memahami pola semantik yang kompleks.

## Tujuan
Tujuan dari proyek ini meliputi:
- Menerapkan lapisan kuantum pada model bahasa besar seperti GPT-2 dan T5-small.
- Memanfaatkan prinsip kuantum untuk mengoptimalkan representasi kata dan kalimat dalam Word2Vec.
- Mengeksplorasi kombinasi antara teknik klasik dan kuantum dalam NLP untuk meningkatkan kinerja dan efisiensi.

## Struktur Folder
- `notebook-research` : folder ini berisi semua notebook penelitian